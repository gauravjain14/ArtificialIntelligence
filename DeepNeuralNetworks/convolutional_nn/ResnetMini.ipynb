{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper-parameters\n",
    "num_epochs = 80\n",
    "batch_size = 100\n",
    "learning_rate = 0.001\n",
    "\n",
    "# Image preprocessing modules\n",
    "transform = transforms.Compose([\n",
    "    transforms.Pad(4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomCrop(32),\n",
    "    transforms.ToTensor()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                        download=True, transform=transform)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = torch.utils.data.DataLoader(dataset=trainset,batch_size=4,\n",
    "                                         shuffle=True,num_workers=2)\n",
    "testloader = torch.utils.data.DataLoader(dataset=testset,batch_size=100,\n",
    "                                         shuffle=True,num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is one residual block\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self,in_channels,out_channels,stride=1,downsample=None):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels,out_channels,kernel_size=3,stride=stride, \\\n",
    "                              padding=1,bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(num_features=out_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = nn.Conv2d(out_channels,out_channels,kernel_size=3,stride=1, \\\n",
    "                              padding=1,bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(num_features=out_channels)\n",
    "        self.downsample = downsample\n",
    "        \n",
    "    def forward(self,x):\n",
    "        residual = x\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        if self.downsample:\n",
    "            residual = self.downsample(residual)\n",
    "        x += residual\n",
    "        x = self.relu(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## According to resnet architecture - (mellowed down by PyTorch)\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self,block,layers,num_classes=10):\n",
    "        super(ResNet,self).__init__()\n",
    "        self.in_channels = 16\n",
    "        self.conv = nn.Conv2d(3,16,kernel_size=3,stride=1, \\\n",
    "                              padding=1,bias=False)\n",
    "        self.bn = nn.BatchNorm2d(num_features=16)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.layer1 = self.make_layer(block, 16, layers[0])\n",
    "        self.layer2 = self.make_layer(block, 32, layers[1], 2)\n",
    "        self.layer3 = self.make_layer(block, 64, layers[2], 2)\n",
    "        self.avg_pool = nn.AvgPool2d(8)\n",
    "        self.fc = nn.Linear(64, num_classes)\n",
    "        \n",
    "    def make_layer(self,block,out_channels,blocks,stride=1):\n",
    "        downsample = None\n",
    "        if (self.in_channels != out_channels) or (stride != 1):\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.in_channels,out_channels,kernel_size=3,stride=stride, \\\n",
    "                              padding=1,bias=False), \\\n",
    "                nn.BatchNorm2d(out_channels))\n",
    "        layers = []\n",
    "        layers.append(block(self.in_channels, out_channels, stride, downsample))\n",
    "        self.in_channels = out_channels\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(out_channels, out_channels))\n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.conv(x)\n",
    "        out = self.bn(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.avg_pool(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "    \n",
    "model = ResNet(ResidualBlock, [2, 2, 2]).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/80], Step [100/12500] Loss: 2.5587\n",
      "Epoch [1/80], Step [200/12500] Loss: 2.1955\n",
      "Epoch [1/80], Step [300/12500] Loss: 1.8618\n",
      "Epoch [1/80], Step [400/12500] Loss: 2.0797\n",
      "Epoch [1/80], Step [500/12500] Loss: 1.6879\n",
      "Epoch [1/80], Step [600/12500] Loss: 2.0044\n",
      "Epoch [1/80], Step [700/12500] Loss: 2.0169\n",
      "Epoch [1/80], Step [800/12500] Loss: 2.2538\n",
      "Epoch [1/80], Step [900/12500] Loss: 2.1079\n",
      "Epoch [1/80], Step [1000/12500] Loss: 2.1439\n",
      "Epoch [1/80], Step [1100/12500] Loss: 1.5376\n",
      "Epoch [1/80], Step [1200/12500] Loss: 1.9431\n",
      "Epoch [1/80], Step [1300/12500] Loss: 1.9862\n",
      "Epoch [1/80], Step [1400/12500] Loss: 2.7970\n",
      "Epoch [1/80], Step [1500/12500] Loss: 1.8451\n",
      "Epoch [1/80], Step [1600/12500] Loss: 1.8750\n",
      "Epoch [1/80], Step [1700/12500] Loss: 2.0855\n",
      "Epoch [1/80], Step [1800/12500] Loss: 2.0999\n",
      "Epoch [1/80], Step [1900/12500] Loss: 1.4392\n",
      "Epoch [1/80], Step [2000/12500] Loss: 2.3268\n",
      "Epoch [1/80], Step [2100/12500] Loss: 1.8443\n",
      "Epoch [1/80], Step [2200/12500] Loss: 1.6540\n",
      "Epoch [1/80], Step [2300/12500] Loss: 1.5852\n",
      "Epoch [1/80], Step [2400/12500] Loss: 2.0493\n",
      "Epoch [1/80], Step [2500/12500] Loss: 2.0646\n",
      "Epoch [1/80], Step [2600/12500] Loss: 1.6108\n",
      "Epoch [1/80], Step [2700/12500] Loss: 2.2668\n",
      "Epoch [1/80], Step [2800/12500] Loss: 2.0313\n",
      "Epoch [1/80], Step [2900/12500] Loss: 2.0048\n",
      "Epoch [1/80], Step [3000/12500] Loss: 1.8672\n",
      "Epoch [1/80], Step [3100/12500] Loss: 1.2390\n",
      "Epoch [1/80], Step [3200/12500] Loss: 1.6258\n",
      "Epoch [1/80], Step [3300/12500] Loss: 1.3530\n",
      "Epoch [1/80], Step [3400/12500] Loss: 1.2407\n",
      "Epoch [1/80], Step [3500/12500] Loss: 1.3979\n",
      "Epoch [1/80], Step [3600/12500] Loss: 1.9474\n",
      "Epoch [1/80], Step [3700/12500] Loss: 2.1688\n",
      "Epoch [1/80], Step [3800/12500] Loss: 2.9912\n",
      "Epoch [1/80], Step [3900/12500] Loss: 1.7621\n",
      "Epoch [1/80], Step [4000/12500] Loss: 1.6045\n",
      "Epoch [1/80], Step [4100/12500] Loss: 1.3807\n",
      "Epoch [1/80], Step [4200/12500] Loss: 0.7676\n",
      "Epoch [1/80], Step [4300/12500] Loss: 1.2249\n",
      "Epoch [1/80], Step [4400/12500] Loss: 2.4438\n",
      "Epoch [1/80], Step [4500/12500] Loss: 1.5960\n",
      "Epoch [1/80], Step [4600/12500] Loss: 1.7136\n",
      "Epoch [1/80], Step [4700/12500] Loss: 1.8475\n",
      "Epoch [1/80], Step [4800/12500] Loss: 1.3425\n",
      "Epoch [1/80], Step [4900/12500] Loss: 1.1403\n",
      "Epoch [1/80], Step [5000/12500] Loss: 1.1043\n",
      "Epoch [1/80], Step [5100/12500] Loss: 1.4869\n",
      "Epoch [1/80], Step [5200/12500] Loss: 2.3401\n",
      "Epoch [1/80], Step [5300/12500] Loss: 1.0871\n",
      "Epoch [1/80], Step [5400/12500] Loss: 2.8654\n",
      "Epoch [1/80], Step [5500/12500] Loss: 0.9563\n",
      "Epoch [1/80], Step [5600/12500] Loss: 1.1426\n",
      "Epoch [1/80], Step [5700/12500] Loss: 1.3274\n",
      "Epoch [1/80], Step [5800/12500] Loss: 2.3952\n",
      "Epoch [1/80], Step [5900/12500] Loss: 1.7624\n",
      "Epoch [1/80], Step [6000/12500] Loss: 0.9717\n",
      "Epoch [1/80], Step [6100/12500] Loss: 0.9696\n",
      "Epoch [1/80], Step [6200/12500] Loss: 2.1260\n",
      "Epoch [1/80], Step [6300/12500] Loss: 1.1745\n",
      "Epoch [1/80], Step [6400/12500] Loss: 1.2642\n",
      "Epoch [1/80], Step [6500/12500] Loss: 1.4673\n",
      "Epoch [1/80], Step [6600/12500] Loss: 1.4955\n",
      "Epoch [1/80], Step [6700/12500] Loss: 1.1592\n",
      "Epoch [1/80], Step [6800/12500] Loss: 1.8786\n",
      "Epoch [1/80], Step [6900/12500] Loss: 1.8838\n",
      "Epoch [1/80], Step [7000/12500] Loss: 1.7263\n",
      "Epoch [1/80], Step [7100/12500] Loss: 1.6423\n",
      "Epoch [1/80], Step [7200/12500] Loss: 1.9192\n",
      "Epoch [1/80], Step [7300/12500] Loss: 1.1172\n",
      "Epoch [1/80], Step [7400/12500] Loss: 1.2110\n",
      "Epoch [1/80], Step [7500/12500] Loss: 1.7534\n",
      "Epoch [1/80], Step [7600/12500] Loss: 1.7766\n",
      "Epoch [1/80], Step [7700/12500] Loss: 1.4969\n",
      "Epoch [1/80], Step [7800/12500] Loss: 2.2415\n",
      "Epoch [1/80], Step [7900/12500] Loss: 2.0533\n",
      "Epoch [1/80], Step [8000/12500] Loss: 1.0294\n",
      "Epoch [1/80], Step [8100/12500] Loss: 1.1394\n",
      "Epoch [1/80], Step [8200/12500] Loss: 0.9890\n",
      "Epoch [1/80], Step [8300/12500] Loss: 1.0182\n",
      "Epoch [1/80], Step [8400/12500] Loss: 1.0488\n",
      "Epoch [1/80], Step [8500/12500] Loss: 1.0523\n",
      "Epoch [1/80], Step [8600/12500] Loss: 1.4853\n",
      "Epoch [1/80], Step [8700/12500] Loss: 1.0996\n",
      "Epoch [1/80], Step [8800/12500] Loss: 0.9671\n",
      "Epoch [1/80], Step [8900/12500] Loss: 1.7031\n",
      "Epoch [1/80], Step [9000/12500] Loss: 0.8297\n",
      "Epoch [1/80], Step [9100/12500] Loss: 1.5119\n",
      "Epoch [1/80], Step [9200/12500] Loss: 0.9611\n",
      "Epoch [1/80], Step [9300/12500] Loss: 1.6984\n",
      "Epoch [1/80], Step [9400/12500] Loss: 1.3751\n",
      "Epoch [1/80], Step [9500/12500] Loss: 1.9778\n",
      "Epoch [1/80], Step [9600/12500] Loss: 0.6612\n",
      "Epoch [1/80], Step [9700/12500] Loss: 1.4249\n",
      "Epoch [1/80], Step [9800/12500] Loss: 0.9190\n",
      "Epoch [1/80], Step [9900/12500] Loss: 1.7432\n",
      "Epoch [1/80], Step [10000/12500] Loss: 0.8651\n",
      "Epoch [1/80], Step [10100/12500] Loss: 1.4672\n",
      "Epoch [1/80], Step [10200/12500] Loss: 1.7888\n",
      "Epoch [1/80], Step [10300/12500] Loss: 1.3422\n",
      "Epoch [1/80], Step [10400/12500] Loss: 1.0551\n",
      "Epoch [1/80], Step [10500/12500] Loss: 1.8032\n",
      "Epoch [1/80], Step [10600/12500] Loss: 1.6940\n",
      "Epoch [1/80], Step [10700/12500] Loss: 1.7702\n",
      "Epoch [1/80], Step [10800/12500] Loss: 1.0935\n",
      "Epoch [1/80], Step [10900/12500] Loss: 1.6269\n",
      "Epoch [1/80], Step [11000/12500] Loss: 1.2376\n",
      "Epoch [1/80], Step [11100/12500] Loss: 2.2375\n",
      "Epoch [1/80], Step [11200/12500] Loss: 1.1774\n",
      "Epoch [1/80], Step [11300/12500] Loss: 0.5891\n",
      "Epoch [1/80], Step [11400/12500] Loss: 1.8304\n",
      "Epoch [1/80], Step [11500/12500] Loss: 1.2575\n",
      "Epoch [1/80], Step [11600/12500] Loss: 2.5944\n",
      "Epoch [1/80], Step [11700/12500] Loss: 2.7716\n",
      "Epoch [1/80], Step [11800/12500] Loss: 2.9620\n",
      "Epoch [1/80], Step [11900/12500] Loss: 1.6267\n",
      "Epoch [1/80], Step [12000/12500] Loss: 1.0597\n",
      "Epoch [1/80], Step [12100/12500] Loss: 0.7515\n",
      "Epoch [1/80], Step [12200/12500] Loss: 1.2224\n",
      "Epoch [1/80], Step [12300/12500] Loss: 1.2670\n",
      "Epoch [1/80], Step [12400/12500] Loss: 1.8324\n",
      "Epoch [1/80], Step [12500/12500] Loss: 0.2447\n",
      "Epoch [2/80], Step [100/12500] Loss: 1.9200\n",
      "Epoch [2/80], Step [200/12500] Loss: 1.0725\n",
      "Epoch [2/80], Step [300/12500] Loss: 1.3151\n",
      "Epoch [2/80], Step [400/12500] Loss: 1.4423\n",
      "Epoch [2/80], Step [500/12500] Loss: 1.5389\n",
      "Epoch [2/80], Step [600/12500] Loss: 0.6294\n",
      "Epoch [2/80], Step [700/12500] Loss: 0.7614\n",
      "Epoch [2/80], Step [800/12500] Loss: 1.6812\n",
      "Epoch [2/80], Step [900/12500] Loss: 1.2321\n",
      "Epoch [2/80], Step [1000/12500] Loss: 1.1993\n",
      "Epoch [2/80], Step [1100/12500] Loss: 1.7282\n",
      "Epoch [2/80], Step [1200/12500] Loss: 0.4469\n",
      "Epoch [2/80], Step [1300/12500] Loss: 1.1870\n",
      "Epoch [2/80], Step [1400/12500] Loss: 0.3740\n",
      "Epoch [2/80], Step [1500/12500] Loss: 0.8015\n",
      "Epoch [2/80], Step [1600/12500] Loss: 1.4616\n",
      "Epoch [2/80], Step [1700/12500] Loss: 1.3061\n",
      "Epoch [2/80], Step [1800/12500] Loss: 1.4224\n",
      "Epoch [2/80], Step [1900/12500] Loss: 1.8231\n",
      "Epoch [2/80], Step [2000/12500] Loss: 1.1029\n",
      "Epoch [2/80], Step [2100/12500] Loss: 1.4729\n",
      "Epoch [2/80], Step [2200/12500] Loss: 2.2084\n",
      "Epoch [2/80], Step [2300/12500] Loss: 2.1753\n",
      "Epoch [2/80], Step [2400/12500] Loss: 1.5947\n",
      "Epoch [2/80], Step [2500/12500] Loss: 1.2937\n",
      "Epoch [2/80], Step [2600/12500] Loss: 0.9489\n",
      "Epoch [2/80], Step [2700/12500] Loss: 0.8763\n",
      "Epoch [2/80], Step [2800/12500] Loss: 1.5236\n",
      "Epoch [2/80], Step [2900/12500] Loss: 1.1934\n",
      "Epoch [2/80], Step [3000/12500] Loss: 1.7100\n",
      "Epoch [2/80], Step [3100/12500] Loss: 2.1127\n",
      "Epoch [2/80], Step [3200/12500] Loss: 0.5427\n",
      "Epoch [2/80], Step [3300/12500] Loss: 0.5510\n",
      "Epoch [2/80], Step [3400/12500] Loss: 0.5618\n",
      "Epoch [2/80], Step [3500/12500] Loss: 1.0668\n",
      "Epoch [2/80], Step [3600/12500] Loss: 0.4942\n",
      "Epoch [2/80], Step [3700/12500] Loss: 2.2049\n",
      "Epoch [2/80], Step [3800/12500] Loss: 1.0389\n",
      "Epoch [2/80], Step [3900/12500] Loss: 0.7415\n",
      "Epoch [2/80], Step [4000/12500] Loss: 0.9470\n",
      "Epoch [2/80], Step [4100/12500] Loss: 1.3371\n",
      "Epoch [2/80], Step [4200/12500] Loss: 1.8307\n",
      "Epoch [2/80], Step [4300/12500] Loss: 0.6342\n",
      "Epoch [2/80], Step [4400/12500] Loss: 1.0621\n",
      "Epoch [2/80], Step [4500/12500] Loss: 0.8652\n",
      "Epoch [2/80], Step [4600/12500] Loss: 0.4404\n",
      "Epoch [2/80], Step [4700/12500] Loss: 0.6652\n",
      "Epoch [2/80], Step [4800/12500] Loss: 1.1887\n",
      "Epoch [2/80], Step [4900/12500] Loss: 0.7138\n",
      "Epoch [2/80], Step [5000/12500] Loss: 0.5949\n",
      "Epoch [2/80], Step [5100/12500] Loss: 1.3137\n",
      "Epoch [2/80], Step [5200/12500] Loss: 2.2282\n",
      "Epoch [2/80], Step [5300/12500] Loss: 0.9881\n",
      "Epoch [2/80], Step [5400/12500] Loss: 0.5197\n",
      "Epoch [2/80], Step [5500/12500] Loss: 0.3367\n",
      "Epoch [2/80], Step [5600/12500] Loss: 1.6802\n",
      "Epoch [2/80], Step [5700/12500] Loss: 0.7121\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/80], Step [5800/12500] Loss: 0.4902\n",
      "Epoch [2/80], Step [5900/12500] Loss: 1.4300\n",
      "Epoch [2/80], Step [6000/12500] Loss: 1.3151\n",
      "Epoch [2/80], Step [6100/12500] Loss: 1.2521\n",
      "Epoch [2/80], Step [6200/12500] Loss: 0.8263\n",
      "Epoch [2/80], Step [6300/12500] Loss: 0.6794\n",
      "Epoch [2/80], Step [6400/12500] Loss: 0.7500\n",
      "Epoch [2/80], Step [6500/12500] Loss: 0.9534\n",
      "Epoch [2/80], Step [6600/12500] Loss: 1.1327\n",
      "Epoch [2/80], Step [6700/12500] Loss: 1.1782\n",
      "Epoch [2/80], Step [6800/12500] Loss: 0.7276\n",
      "Epoch [2/80], Step [6900/12500] Loss: 0.2783\n",
      "Epoch [2/80], Step [7000/12500] Loss: 0.6306\n",
      "Epoch [2/80], Step [7100/12500] Loss: 1.5533\n",
      "Epoch [2/80], Step [7200/12500] Loss: 1.5356\n",
      "Epoch [2/80], Step [7300/12500] Loss: 0.5336\n",
      "Epoch [2/80], Step [7400/12500] Loss: 1.5859\n",
      "Epoch [2/80], Step [7500/12500] Loss: 0.4513\n",
      "Epoch [2/80], Step [7600/12500] Loss: 1.0298\n",
      "Epoch [2/80], Step [7700/12500] Loss: 0.8559\n",
      "Epoch [2/80], Step [7800/12500] Loss: 0.3866\n",
      "Epoch [2/80], Step [7900/12500] Loss: 1.7260\n",
      "Epoch [2/80], Step [8000/12500] Loss: 0.8102\n",
      "Epoch [2/80], Step [8100/12500] Loss: 0.8816\n",
      "Epoch [2/80], Step [8200/12500] Loss: 1.0915\n",
      "Epoch [2/80], Step [8300/12500] Loss: 0.6641\n",
      "Epoch [2/80], Step [8400/12500] Loss: 0.9076\n",
      "Epoch [2/80], Step [8500/12500] Loss: 0.5678\n",
      "Epoch [2/80], Step [8600/12500] Loss: 1.0644\n",
      "Epoch [2/80], Step [8700/12500] Loss: 1.0499\n",
      "Epoch [2/80], Step [8800/12500] Loss: 0.1660\n",
      "Epoch [2/80], Step [8900/12500] Loss: 0.8022\n",
      "Epoch [2/80], Step [9000/12500] Loss: 1.0769\n",
      "Epoch [2/80], Step [9100/12500] Loss: 1.1767\n",
      "Epoch [2/80], Step [9200/12500] Loss: 0.5262\n",
      "Epoch [2/80], Step [9300/12500] Loss: 1.7092\n",
      "Epoch [2/80], Step [9400/12500] Loss: 0.7924\n",
      "Epoch [2/80], Step [9500/12500] Loss: 1.2354\n",
      "Epoch [2/80], Step [9600/12500] Loss: 2.4388\n",
      "Epoch [2/80], Step [9700/12500] Loss: 0.9414\n",
      "Epoch [2/80], Step [9800/12500] Loss: 1.1712\n",
      "Epoch [2/80], Step [9900/12500] Loss: 0.3514\n",
      "Epoch [2/80], Step [10000/12500] Loss: 0.5073\n",
      "Epoch [2/80], Step [10100/12500] Loss: 1.5841\n",
      "Epoch [2/80], Step [10200/12500] Loss: 0.3659\n",
      "Epoch [2/80], Step [10300/12500] Loss: 0.6028\n",
      "Epoch [2/80], Step [10400/12500] Loss: 1.8729\n",
      "Epoch [2/80], Step [10500/12500] Loss: 0.8817\n",
      "Epoch [2/80], Step [10600/12500] Loss: 1.2725\n",
      "Epoch [2/80], Step [10700/12500] Loss: 0.2500\n",
      "Epoch [2/80], Step [10800/12500] Loss: 2.0728\n",
      "Epoch [2/80], Step [10900/12500] Loss: 0.5626\n",
      "Epoch [2/80], Step [11000/12500] Loss: 0.7466\n",
      "Epoch [2/80], Step [11100/12500] Loss: 1.2762\n",
      "Epoch [2/80], Step [11200/12500] Loss: 0.5767\n",
      "Epoch [2/80], Step [11300/12500] Loss: 0.3621\n",
      "Epoch [2/80], Step [11400/12500] Loss: 0.6638\n",
      "Epoch [2/80], Step [11500/12500] Loss: 0.4958\n",
      "Epoch [2/80], Step [11600/12500] Loss: 1.4204\n",
      "Epoch [2/80], Step [11700/12500] Loss: 0.7218\n",
      "Epoch [2/80], Step [11800/12500] Loss: 0.6745\n",
      "Epoch [2/80], Step [11900/12500] Loss: 1.8355\n",
      "Epoch [2/80], Step [12000/12500] Loss: 0.8326\n",
      "Epoch [2/80], Step [12100/12500] Loss: 0.4237\n",
      "Epoch [2/80], Step [12200/12500] Loss: 1.0587\n",
      "Epoch [2/80], Step [12300/12500] Loss: 2.6810\n",
      "Epoch [2/80], Step [12400/12500] Loss: 1.1908\n",
      "Epoch [2/80], Step [12500/12500] Loss: 1.5539\n",
      "Epoch [3/80], Step [100/12500] Loss: 2.0995\n",
      "Epoch [3/80], Step [200/12500] Loss: 0.9852\n",
      "Epoch [3/80], Step [300/12500] Loss: 0.8185\n",
      "Epoch [3/80], Step [400/12500] Loss: 0.3618\n",
      "Epoch [3/80], Step [500/12500] Loss: 0.9128\n",
      "Epoch [3/80], Step [600/12500] Loss: 0.5706\n",
      "Epoch [3/80], Step [700/12500] Loss: 0.8570\n",
      "Epoch [3/80], Step [800/12500] Loss: 0.4797\n",
      "Epoch [3/80], Step [900/12500] Loss: 0.6127\n",
      "Epoch [3/80], Step [1000/12500] Loss: 0.3333\n",
      "Epoch [3/80], Step [1100/12500] Loss: 0.3339\n",
      "Epoch [3/80], Step [1200/12500] Loss: 0.4406\n",
      "Epoch [3/80], Step [1300/12500] Loss: 1.1369\n",
      "Epoch [3/80], Step [1400/12500] Loss: 1.4844\n",
      "Epoch [3/80], Step [1500/12500] Loss: 0.7648\n",
      "Epoch [3/80], Step [1600/12500] Loss: 0.6981\n",
      "Epoch [3/80], Step [1700/12500] Loss: 0.4598\n",
      "Epoch [3/80], Step [1800/12500] Loss: 0.9813\n",
      "Epoch [3/80], Step [1900/12500] Loss: 1.1447\n",
      "Epoch [3/80], Step [2000/12500] Loss: 1.3024\n",
      "Epoch [3/80], Step [2100/12500] Loss: 1.5253\n",
      "Epoch [3/80], Step [2200/12500] Loss: 0.7304\n",
      "Epoch [3/80], Step [2300/12500] Loss: 0.4355\n",
      "Epoch [3/80], Step [2400/12500] Loss: 0.1401\n",
      "Epoch [3/80], Step [2500/12500] Loss: 0.4272\n",
      "Epoch [3/80], Step [2600/12500] Loss: 1.4803\n",
      "Epoch [3/80], Step [2700/12500] Loss: 1.1881\n",
      "Epoch [3/80], Step [2800/12500] Loss: 0.5179\n",
      "Epoch [3/80], Step [2900/12500] Loss: 1.4849\n",
      "Epoch [3/80], Step [3000/12500] Loss: 0.8558\n",
      "Epoch [3/80], Step [3100/12500] Loss: 1.1038\n",
      "Epoch [3/80], Step [3200/12500] Loss: 0.9136\n",
      "Epoch [3/80], Step [3300/12500] Loss: 0.4877\n",
      "Epoch [3/80], Step [3400/12500] Loss: 1.2778\n",
      "Epoch [3/80], Step [3500/12500] Loss: 0.5307\n",
      "Epoch [3/80], Step [3600/12500] Loss: 0.5881\n",
      "Epoch [3/80], Step [3700/12500] Loss: 0.6257\n",
      "Epoch [3/80], Step [3800/12500] Loss: 1.0056\n",
      "Epoch [3/80], Step [3900/12500] Loss: 1.0117\n",
      "Epoch [3/80], Step [4000/12500] Loss: 0.5674\n",
      "Epoch [3/80], Step [4100/12500] Loss: 1.6831\n",
      "Epoch [3/80], Step [4200/12500] Loss: 1.8614\n",
      "Epoch [3/80], Step [4300/12500] Loss: 1.2616\n",
      "Epoch [3/80], Step [4400/12500] Loss: 1.0658\n",
      "Epoch [3/80], Step [4500/12500] Loss: 0.4882\n",
      "Epoch [3/80], Step [4600/12500] Loss: 1.0881\n",
      "Epoch [3/80], Step [4700/12500] Loss: 1.3995\n",
      "Epoch [3/80], Step [4800/12500] Loss: 1.1423\n",
      "Epoch [3/80], Step [4900/12500] Loss: 0.4634\n",
      "Epoch [3/80], Step [5000/12500] Loss: 2.6831\n",
      "Epoch [3/80], Step [5100/12500] Loss: 1.4813\n",
      "Epoch [3/80], Step [5200/12500] Loss: 0.5521\n",
      "Epoch [3/80], Step [5300/12500] Loss: 1.2860\n",
      "Epoch [3/80], Step [5400/12500] Loss: 2.1547\n",
      "Epoch [3/80], Step [5500/12500] Loss: 0.8006\n",
      "Epoch [3/80], Step [5600/12500] Loss: 0.6879\n",
      "Epoch [3/80], Step [5700/12500] Loss: 1.1146\n",
      "Epoch [3/80], Step [5800/12500] Loss: 1.5219\n",
      "Epoch [3/80], Step [5900/12500] Loss: 1.5833\n",
      "Epoch [3/80], Step [6000/12500] Loss: 0.3775\n",
      "Epoch [3/80], Step [6100/12500] Loss: 2.3438\n",
      "Epoch [3/80], Step [6200/12500] Loss: 0.2354\n",
      "Epoch [3/80], Step [6300/12500] Loss: 0.9072\n",
      "Epoch [3/80], Step [6400/12500] Loss: 1.6815\n",
      "Epoch [3/80], Step [6500/12500] Loss: 1.4193\n",
      "Epoch [3/80], Step [6600/12500] Loss: 1.3751\n",
      "Epoch [3/80], Step [6700/12500] Loss: 0.9258\n",
      "Epoch [3/80], Step [6800/12500] Loss: 0.9569\n",
      "Epoch [3/80], Step [6900/12500] Loss: 0.5234\n",
      "Epoch [3/80], Step [7000/12500] Loss: 2.1471\n",
      "Epoch [3/80], Step [7100/12500] Loss: 0.8507\n",
      "Epoch [3/80], Step [7200/12500] Loss: 0.4914\n",
      "Epoch [3/80], Step [7300/12500] Loss: 1.1661\n",
      "Epoch [3/80], Step [7400/12500] Loss: 1.4157\n",
      "Epoch [3/80], Step [7500/12500] Loss: 0.3827\n",
      "Epoch [3/80], Step [7600/12500] Loss: 1.0315\n",
      "Epoch [3/80], Step [7700/12500] Loss: 0.5337\n",
      "Epoch [3/80], Step [7800/12500] Loss: 1.5922\n",
      "Epoch [3/80], Step [7900/12500] Loss: 1.3765\n",
      "Epoch [3/80], Step [8000/12500] Loss: 0.9168\n",
      "Epoch [3/80], Step [8100/12500] Loss: 1.8302\n",
      "Epoch [3/80], Step [8200/12500] Loss: 0.4885\n",
      "Epoch [3/80], Step [8300/12500] Loss: 0.5662\n",
      "Epoch [3/80], Step [8400/12500] Loss: 1.0879\n",
      "Epoch [3/80], Step [8500/12500] Loss: 0.0148\n",
      "Epoch [3/80], Step [8600/12500] Loss: 0.5685\n",
      "Epoch [3/80], Step [8700/12500] Loss: 1.3209\n",
      "Epoch [3/80], Step [8800/12500] Loss: 0.8519\n",
      "Epoch [3/80], Step [8900/12500] Loss: 1.5092\n",
      "Epoch [3/80], Step [9000/12500] Loss: 0.9240\n",
      "Epoch [3/80], Step [9100/12500] Loss: 2.4515\n",
      "Epoch [3/80], Step [9200/12500] Loss: 0.7048\n",
      "Epoch [3/80], Step [9300/12500] Loss: 0.9842\n",
      "Epoch [3/80], Step [9400/12500] Loss: 0.5393\n",
      "Epoch [3/80], Step [9500/12500] Loss: 0.7653\n",
      "Epoch [3/80], Step [9600/12500] Loss: 0.5557\n",
      "Epoch [3/80], Step [9700/12500] Loss: 0.6434\n",
      "Epoch [3/80], Step [9800/12500] Loss: 0.6831\n",
      "Epoch [3/80], Step [9900/12500] Loss: 1.4011\n",
      "Epoch [3/80], Step [10000/12500] Loss: 1.5510\n",
      "Epoch [3/80], Step [10100/12500] Loss: 0.4407\n",
      "Epoch [3/80], Step [10200/12500] Loss: 1.1249\n",
      "Epoch [3/80], Step [10300/12500] Loss: 0.5915\n",
      "Epoch [3/80], Step [10400/12500] Loss: 0.8194\n",
      "Epoch [3/80], Step [10500/12500] Loss: 0.2707\n",
      "Epoch [3/80], Step [10600/12500] Loss: 2.9243\n",
      "Epoch [3/80], Step [10700/12500] Loss: 0.0774\n",
      "Epoch [3/80], Step [10800/12500] Loss: 1.4335\n",
      "Epoch [3/80], Step [10900/12500] Loss: 0.9299\n",
      "Epoch [3/80], Step [11000/12500] Loss: 0.7076\n",
      "Epoch [3/80], Step [11100/12500] Loss: 1.0480\n",
      "Epoch [3/80], Step [11200/12500] Loss: 1.7251\n",
      "Epoch [3/80], Step [11300/12500] Loss: 1.6411\n",
      "Epoch [3/80], Step [11400/12500] Loss: 1.4177\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/80], Step [11500/12500] Loss: 0.4964\n",
      "Epoch [3/80], Step [11600/12500] Loss: 0.3307\n",
      "Epoch [3/80], Step [11700/12500] Loss: 0.5795\n",
      "Epoch [3/80], Step [11800/12500] Loss: 0.5361\n",
      "Epoch [3/80], Step [11900/12500] Loss: 0.4238\n",
      "Epoch [3/80], Step [12000/12500] Loss: 2.1658\n",
      "Epoch [3/80], Step [12100/12500] Loss: 0.2953\n",
      "Epoch [3/80], Step [12200/12500] Loss: 0.5139\n",
      "Epoch [3/80], Step [12300/12500] Loss: 1.1611\n",
      "Epoch [3/80], Step [12400/12500] Loss: 0.8456\n",
      "Epoch [3/80], Step [12500/12500] Loss: 0.4712\n",
      "Epoch [4/80], Step [100/12500] Loss: 0.3636\n",
      "Epoch [4/80], Step [200/12500] Loss: 1.2258\n",
      "Epoch [4/80], Step [300/12500] Loss: 1.0139\n",
      "Epoch [4/80], Step [400/12500] Loss: 2.1005\n",
      "Epoch [4/80], Step [500/12500] Loss: 1.1643\n",
      "Epoch [4/80], Step [600/12500] Loss: 0.2739\n",
      "Epoch [4/80], Step [700/12500] Loss: 1.2365\n",
      "Epoch [4/80], Step [800/12500] Loss: 0.4014\n",
      "Epoch [4/80], Step [900/12500] Loss: 0.9463\n",
      "Epoch [4/80], Step [1000/12500] Loss: 1.7920\n",
      "Epoch [4/80], Step [1100/12500] Loss: 1.1772\n",
      "Epoch [4/80], Step [1200/12500] Loss: 0.4005\n",
      "Epoch [4/80], Step [1300/12500] Loss: 0.6357\n",
      "Epoch [4/80], Step [1400/12500] Loss: 0.2330\n",
      "Epoch [4/80], Step [1500/12500] Loss: 0.1541\n",
      "Epoch [4/80], Step [1600/12500] Loss: 0.4497\n",
      "Epoch [4/80], Step [1700/12500] Loss: 0.5730\n",
      "Epoch [4/80], Step [1800/12500] Loss: 0.7443\n",
      "Epoch [4/80], Step [1900/12500] Loss: 0.4525\n",
      "Epoch [4/80], Step [2000/12500] Loss: 1.2337\n",
      "Epoch [4/80], Step [2100/12500] Loss: 1.6563\n",
      "Epoch [4/80], Step [2200/12500] Loss: 0.7373\n",
      "Epoch [4/80], Step [2300/12500] Loss: 0.5855\n",
      "Epoch [4/80], Step [2400/12500] Loss: 0.6491\n",
      "Epoch [4/80], Step [2500/12500] Loss: 1.2896\n",
      "Epoch [4/80], Step [2600/12500] Loss: 0.4655\n",
      "Epoch [4/80], Step [2700/12500] Loss: 0.6255\n",
      "Epoch [4/80], Step [2800/12500] Loss: 0.2055\n",
      "Epoch [4/80], Step [2900/12500] Loss: 1.7228\n",
      "Epoch [4/80], Step [3000/12500] Loss: 0.9212\n",
      "Epoch [4/80], Step [3100/12500] Loss: 0.4131\n",
      "Epoch [4/80], Step [3200/12500] Loss: 1.1737\n",
      "Epoch [4/80], Step [3300/12500] Loss: 0.4452\n",
      "Epoch [4/80], Step [3400/12500] Loss: 0.5353\n",
      "Epoch [4/80], Step [3500/12500] Loss: 0.8379\n",
      "Epoch [4/80], Step [3600/12500] Loss: 0.6506\n",
      "Epoch [4/80], Step [3700/12500] Loss: 1.3673\n",
      "Epoch [4/80], Step [3800/12500] Loss: 1.9088\n",
      "Epoch [4/80], Step [3900/12500] Loss: 0.4831\n",
      "Epoch [4/80], Step [4000/12500] Loss: 1.3964\n",
      "Epoch [4/80], Step [4100/12500] Loss: 0.4387\n",
      "Epoch [4/80], Step [4200/12500] Loss: 0.8441\n",
      "Epoch [4/80], Step [4300/12500] Loss: 0.6281\n",
      "Epoch [4/80], Step [4400/12500] Loss: 0.3222\n",
      "Epoch [4/80], Step [4500/12500] Loss: 0.5392\n",
      "Epoch [4/80], Step [4600/12500] Loss: 0.9905\n",
      "Epoch [4/80], Step [4700/12500] Loss: 0.9127\n",
      "Epoch [4/80], Step [4800/12500] Loss: 1.9284\n",
      "Epoch [4/80], Step [4900/12500] Loss: 0.1511\n",
      "Epoch [4/80], Step [5000/12500] Loss: 1.2428\n",
      "Epoch [4/80], Step [5100/12500] Loss: 0.7370\n",
      "Epoch [4/80], Step [5200/12500] Loss: 1.2688\n",
      "Epoch [4/80], Step [5300/12500] Loss: 0.1064\n",
      "Epoch [4/80], Step [5400/12500] Loss: 0.8312\n",
      "Epoch [4/80], Step [5500/12500] Loss: 1.4701\n",
      "Epoch [4/80], Step [5600/12500] Loss: 0.2739\n",
      "Epoch [4/80], Step [5700/12500] Loss: 0.7548\n",
      "Epoch [4/80], Step [5800/12500] Loss: 1.3662\n",
      "Epoch [4/80], Step [5900/12500] Loss: 0.0213\n",
      "Epoch [4/80], Step [6000/12500] Loss: 0.8876\n",
      "Epoch [4/80], Step [6100/12500] Loss: 0.3648\n",
      "Epoch [4/80], Step [6200/12500] Loss: 0.9613\n",
      "Epoch [4/80], Step [6300/12500] Loss: 0.8121\n",
      "Epoch [4/80], Step [6400/12500] Loss: 1.6774\n",
      "Epoch [4/80], Step [6500/12500] Loss: 0.1454\n",
      "Epoch [4/80], Step [6600/12500] Loss: 0.3296\n",
      "Epoch [4/80], Step [6700/12500] Loss: 0.8278\n",
      "Epoch [4/80], Step [6800/12500] Loss: 1.5327\n",
      "Epoch [4/80], Step [6900/12500] Loss: 1.0266\n",
      "Epoch [4/80], Step [7000/12500] Loss: 0.8924\n",
      "Epoch [4/80], Step [7100/12500] Loss: 0.3947\n",
      "Epoch [4/80], Step [7200/12500] Loss: 0.8363\n",
      "Epoch [4/80], Step [7300/12500] Loss: 0.5415\n",
      "Epoch [4/80], Step [7400/12500] Loss: 1.4390\n",
      "Epoch [4/80], Step [7500/12500] Loss: 0.6400\n",
      "Epoch [4/80], Step [7600/12500] Loss: 0.4002\n",
      "Epoch [4/80], Step [7700/12500] Loss: 1.3942\n",
      "Epoch [4/80], Step [7800/12500] Loss: 0.1381\n",
      "Epoch [4/80], Step [7900/12500] Loss: 0.3126\n",
      "Epoch [4/80], Step [8000/12500] Loss: 0.4946\n",
      "Epoch [4/80], Step [8100/12500] Loss: 1.0434\n",
      "Epoch [4/80], Step [8200/12500] Loss: 0.5160\n",
      "Epoch [4/80], Step [8300/12500] Loss: 1.2647\n",
      "Epoch [4/80], Step [8400/12500] Loss: 0.7785\n",
      "Epoch [4/80], Step [8500/12500] Loss: 0.1604\n",
      "Epoch [4/80], Step [8600/12500] Loss: 0.5535\n",
      "Epoch [4/80], Step [8700/12500] Loss: 0.1619\n",
      "Epoch [4/80], Step [8800/12500] Loss: 0.7967\n",
      "Epoch [4/80], Step [8900/12500] Loss: 0.8390\n",
      "Epoch [4/80], Step [9000/12500] Loss: 0.1622\n",
      "Epoch [4/80], Step [9100/12500] Loss: 0.5617\n",
      "Epoch [4/80], Step [9200/12500] Loss: 0.4508\n",
      "Epoch [4/80], Step [9300/12500] Loss: 2.7634\n",
      "Epoch [4/80], Step [9400/12500] Loss: 0.9765\n",
      "Epoch [4/80], Step [9500/12500] Loss: 1.1687\n",
      "Epoch [4/80], Step [9600/12500] Loss: 1.2315\n",
      "Epoch [4/80], Step [9700/12500] Loss: 0.5143\n",
      "Epoch [4/80], Step [9800/12500] Loss: 1.0921\n",
      "Epoch [4/80], Step [9900/12500] Loss: 0.7689\n",
      "Epoch [4/80], Step [10000/12500] Loss: 0.2595\n",
      "Epoch [4/80], Step [10100/12500] Loss: 0.3276\n",
      "Epoch [4/80], Step [10200/12500] Loss: 0.8335\n",
      "Epoch [4/80], Step [10300/12500] Loss: 1.1740\n",
      "Epoch [4/80], Step [10400/12500] Loss: 0.1343\n",
      "Epoch [4/80], Step [10500/12500] Loss: 0.8253\n",
      "Epoch [4/80], Step [10600/12500] Loss: 0.5296\n",
      "Epoch [4/80], Step [10700/12500] Loss: 0.3105\n",
      "Epoch [4/80], Step [10800/12500] Loss: 0.4893\n",
      "Epoch [4/80], Step [10900/12500] Loss: 1.1751\n",
      "Epoch [4/80], Step [11000/12500] Loss: 0.7119\n",
      "Epoch [4/80], Step [11100/12500] Loss: 0.3421\n",
      "Epoch [4/80], Step [11200/12500] Loss: 0.0546\n",
      "Epoch [4/80], Step [11300/12500] Loss: 0.4488\n",
      "Epoch [4/80], Step [11400/12500] Loss: 0.2731\n",
      "Epoch [4/80], Step [11500/12500] Loss: 0.3072\n",
      "Epoch [4/80], Step [11600/12500] Loss: 0.4266\n",
      "Epoch [4/80], Step [11700/12500] Loss: 0.2277\n",
      "Epoch [4/80], Step [11800/12500] Loss: 0.9782\n",
      "Epoch [4/80], Step [11900/12500] Loss: 0.2577\n",
      "Epoch [4/80], Step [12000/12500] Loss: 0.6488\n",
      "Epoch [4/80], Step [12100/12500] Loss: 0.4588\n",
      "Epoch [4/80], Step [12200/12500] Loss: 0.3519\n",
      "Epoch [4/80], Step [12300/12500] Loss: 0.3959\n",
      "Epoch [4/80], Step [12400/12500] Loss: 0.9252\n",
      "Epoch [4/80], Step [12500/12500] Loss: 2.0614\n",
      "Epoch [5/80], Step [100/12500] Loss: 1.1532\n",
      "Epoch [5/80], Step [200/12500] Loss: 0.5503\n",
      "Epoch [5/80], Step [300/12500] Loss: 0.7419\n",
      "Epoch [5/80], Step [400/12500] Loss: 0.4296\n",
      "Epoch [5/80], Step [500/12500] Loss: 0.3998\n",
      "Epoch [5/80], Step [600/12500] Loss: 0.2029\n",
      "Epoch [5/80], Step [700/12500] Loss: 0.3248\n",
      "Epoch [5/80], Step [800/12500] Loss: 1.6897\n",
      "Epoch [5/80], Step [900/12500] Loss: 0.1663\n",
      "Epoch [5/80], Step [1000/12500] Loss: 0.3205\n",
      "Epoch [5/80], Step [1100/12500] Loss: 0.4329\n",
      "Epoch [5/80], Step [1200/12500] Loss: 0.4866\n",
      "Epoch [5/80], Step [1300/12500] Loss: 0.2113\n",
      "Epoch [5/80], Step [1400/12500] Loss: 0.9693\n",
      "Epoch [5/80], Step [1500/12500] Loss: 0.5637\n",
      "Epoch [5/80], Step [1600/12500] Loss: 0.5638\n",
      "Epoch [5/80], Step [1700/12500] Loss: 0.4248\n",
      "Epoch [5/80], Step [1800/12500] Loss: 1.8393\n",
      "Epoch [5/80], Step [1900/12500] Loss: 0.4248\n",
      "Epoch [5/80], Step [2000/12500] Loss: 0.3120\n",
      "Epoch [5/80], Step [2100/12500] Loss: 0.7059\n",
      "Epoch [5/80], Step [2200/12500] Loss: 0.5844\n",
      "Epoch [5/80], Step [2300/12500] Loss: 1.0119\n",
      "Epoch [5/80], Step [2400/12500] Loss: 0.2215\n",
      "Epoch [5/80], Step [2500/12500] Loss: 0.3487\n",
      "Epoch [5/80], Step [2600/12500] Loss: 1.5678\n",
      "Epoch [5/80], Step [2700/12500] Loss: 0.3288\n",
      "Epoch [5/80], Step [2800/12500] Loss: 1.1229\n",
      "Epoch [5/80], Step [2900/12500] Loss: 0.2535\n",
      "Epoch [5/80], Step [3000/12500] Loss: 1.0467\n",
      "Epoch [5/80], Step [3100/12500] Loss: 0.7134\n",
      "Epoch [5/80], Step [3200/12500] Loss: 0.3625\n",
      "Epoch [5/80], Step [3300/12500] Loss: 0.2813\n",
      "Epoch [5/80], Step [3400/12500] Loss: 0.2704\n",
      "Epoch [5/80], Step [3500/12500] Loss: 1.2569\n",
      "Epoch [5/80], Step [3600/12500] Loss: 0.2840\n",
      "Epoch [5/80], Step [3700/12500] Loss: 0.6604\n",
      "Epoch [5/80], Step [3800/12500] Loss: 0.3999\n",
      "Epoch [5/80], Step [3900/12500] Loss: 0.6634\n",
      "Epoch [5/80], Step [4000/12500] Loss: 1.2734\n",
      "Epoch [5/80], Step [4100/12500] Loss: 0.5951\n",
      "Epoch [5/80], Step [4200/12500] Loss: 0.0979\n",
      "Epoch [5/80], Step [4300/12500] Loss: 0.6875\n",
      "Epoch [5/80], Step [4400/12500] Loss: 1.2557\n",
      "Epoch [5/80], Step [4500/12500] Loss: 0.2546\n",
      "Epoch [5/80], Step [4600/12500] Loss: 0.4858\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/80], Step [4700/12500] Loss: 0.3702\n",
      "Epoch [5/80], Step [4800/12500] Loss: 0.8521\n",
      "Epoch [5/80], Step [4900/12500] Loss: 0.6622\n",
      "Epoch [5/80], Step [5000/12500] Loss: 0.3122\n",
      "Epoch [5/80], Step [5100/12500] Loss: 0.7799\n",
      "Epoch [5/80], Step [5200/12500] Loss: 0.9384\n",
      "Epoch [5/80], Step [5300/12500] Loss: 0.1481\n",
      "Epoch [5/80], Step [5400/12500] Loss: 1.2869\n",
      "Epoch [5/80], Step [5500/12500] Loss: 0.3616\n",
      "Epoch [5/80], Step [5600/12500] Loss: 0.3593\n",
      "Epoch [5/80], Step [5700/12500] Loss: 0.9036\n",
      "Epoch [5/80], Step [5800/12500] Loss: 0.5923\n",
      "Epoch [5/80], Step [5900/12500] Loss: 0.3758\n",
      "Epoch [5/80], Step [6000/12500] Loss: 0.2418\n",
      "Epoch [5/80], Step [6100/12500] Loss: 0.2888\n",
      "Epoch [5/80], Step [6200/12500] Loss: 0.2900\n",
      "Epoch [5/80], Step [6300/12500] Loss: 1.4569\n",
      "Epoch [5/80], Step [6400/12500] Loss: 0.7032\n",
      "Epoch [5/80], Step [6500/12500] Loss: 0.1317\n",
      "Epoch [5/80], Step [6600/12500] Loss: 1.3302\n",
      "Epoch [5/80], Step [6700/12500] Loss: 0.1302\n",
      "Epoch [5/80], Step [6800/12500] Loss: 0.9650\n",
      "Epoch [5/80], Step [6900/12500] Loss: 0.4589\n",
      "Epoch [5/80], Step [7000/12500] Loss: 0.2629\n",
      "Epoch [5/80], Step [7100/12500] Loss: 0.6862\n",
      "Epoch [5/80], Step [7200/12500] Loss: 0.2222\n",
      "Epoch [5/80], Step [7300/12500] Loss: 0.4593\n",
      "Epoch [5/80], Step [7400/12500] Loss: 0.4118\n",
      "Epoch [5/80], Step [7500/12500] Loss: 0.2305\n",
      "Epoch [5/80], Step [7600/12500] Loss: 1.4063\n",
      "Epoch [5/80], Step [7700/12500] Loss: 1.3734\n",
      "Epoch [5/80], Step [7800/12500] Loss: 0.5815\n",
      "Epoch [5/80], Step [7900/12500] Loss: 0.2828\n",
      "Epoch [5/80], Step [8000/12500] Loss: 0.6079\n",
      "Epoch [5/80], Step [8100/12500] Loss: 0.6475\n",
      "Epoch [5/80], Step [8200/12500] Loss: 0.7002\n",
      "Epoch [5/80], Step [8300/12500] Loss: 0.3875\n",
      "Epoch [5/80], Step [8400/12500] Loss: 0.7110\n",
      "Epoch [5/80], Step [8500/12500] Loss: 0.1945\n",
      "Epoch [5/80], Step [8600/12500] Loss: 0.3209\n",
      "Epoch [5/80], Step [8700/12500] Loss: 0.8698\n",
      "Epoch [5/80], Step [8800/12500] Loss: 1.4281\n",
      "Epoch [5/80], Step [8900/12500] Loss: 0.9215\n",
      "Epoch [5/80], Step [9000/12500] Loss: 0.3172\n",
      "Epoch [5/80], Step [9100/12500] Loss: 0.4071\n",
      "Epoch [5/80], Step [9200/12500] Loss: 0.7700\n",
      "Epoch [5/80], Step [9300/12500] Loss: 0.7001\n",
      "Epoch [5/80], Step [9400/12500] Loss: 0.4452\n",
      "Epoch [5/80], Step [9500/12500] Loss: 0.3295\n",
      "Epoch [5/80], Step [9600/12500] Loss: 0.1549\n",
      "Epoch [5/80], Step [9700/12500] Loss: 0.0801\n",
      "Epoch [5/80], Step [9800/12500] Loss: 0.3090\n",
      "Epoch [5/80], Step [9900/12500] Loss: 0.8016\n",
      "Epoch [5/80], Step [10000/12500] Loss: 1.0002\n",
      "Epoch [5/80], Step [10100/12500] Loss: 0.8679\n",
      "Epoch [5/80], Step [10200/12500] Loss: 0.3387\n",
      "Epoch [5/80], Step [10300/12500] Loss: 0.6211\n",
      "Epoch [5/80], Step [10400/12500] Loss: 0.2490\n",
      "Epoch [5/80], Step [10500/12500] Loss: 0.4195\n",
      "Epoch [5/80], Step [10600/12500] Loss: 0.8296\n",
      "Epoch [5/80], Step [10700/12500] Loss: 0.3187\n",
      "Epoch [5/80], Step [10800/12500] Loss: 0.2683\n",
      "Epoch [5/80], Step [10900/12500] Loss: 1.1059\n",
      "Epoch [5/80], Step [11000/12500] Loss: 1.7351\n",
      "Epoch [5/80], Step [11100/12500] Loss: 0.3300\n",
      "Epoch [5/80], Step [11200/12500] Loss: 1.4237\n",
      "Epoch [5/80], Step [11300/12500] Loss: 0.5344\n",
      "Epoch [5/80], Step [11400/12500] Loss: 0.0286\n",
      "Epoch [5/80], Step [11500/12500] Loss: 0.9618\n",
      "Epoch [5/80], Step [11600/12500] Loss: 1.1387\n",
      "Epoch [5/80], Step [11700/12500] Loss: 0.6828\n",
      "Epoch [5/80], Step [11800/12500] Loss: 0.9877\n",
      "Epoch [5/80], Step [11900/12500] Loss: 1.7180\n",
      "Epoch [5/80], Step [12000/12500] Loss: 2.5711\n",
      "Epoch [5/80], Step [12100/12500] Loss: 1.3469\n",
      "Epoch [5/80], Step [12200/12500] Loss: 0.1743\n",
      "Epoch [5/80], Step [12300/12500] Loss: 0.1576\n",
      "Epoch [5/80], Step [12400/12500] Loss: 0.2943\n",
      "Epoch [5/80], Step [12500/12500] Loss: 0.3022\n",
      "Epoch [6/80], Step [100/12500] Loss: 1.5212\n",
      "Epoch [6/80], Step [200/12500] Loss: 0.6316\n",
      "Epoch [6/80], Step [300/12500] Loss: 0.6541\n",
      "Epoch [6/80], Step [400/12500] Loss: 0.8029\n",
      "Epoch [6/80], Step [500/12500] Loss: 0.6094\n",
      "Epoch [6/80], Step [600/12500] Loss: 0.6206\n",
      "Epoch [6/80], Step [700/12500] Loss: 1.0717\n",
      "Epoch [6/80], Step [800/12500] Loss: 1.2202\n",
      "Epoch [6/80], Step [900/12500] Loss: 0.2890\n",
      "Epoch [6/80], Step [1000/12500] Loss: 0.7180\n",
      "Epoch [6/80], Step [1100/12500] Loss: 1.5511\n",
      "Epoch [6/80], Step [1200/12500] Loss: 0.3269\n",
      "Epoch [6/80], Step [1300/12500] Loss: 0.4623\n",
      "Epoch [6/80], Step [1400/12500] Loss: 0.6231\n",
      "Epoch [6/80], Step [1500/12500] Loss: 0.5403\n",
      "Epoch [6/80], Step [1600/12500] Loss: 0.9155\n",
      "Epoch [6/80], Step [1700/12500] Loss: 0.2297\n",
      "Epoch [6/80], Step [1800/12500] Loss: 0.0909\n",
      "Epoch [6/80], Step [1900/12500] Loss: 0.6568\n",
      "Epoch [6/80], Step [2000/12500] Loss: 1.2412\n",
      "Epoch [6/80], Step [2100/12500] Loss: 0.1575\n",
      "Epoch [6/80], Step [2200/12500] Loss: 0.6177\n",
      "Epoch [6/80], Step [2300/12500] Loss: 0.1365\n",
      "Epoch [6/80], Step [2400/12500] Loss: 0.8599\n",
      "Epoch [6/80], Step [2500/12500] Loss: 0.3116\n",
      "Epoch [6/80], Step [2600/12500] Loss: 0.1528\n",
      "Epoch [6/80], Step [2700/12500] Loss: 0.2129\n",
      "Epoch [6/80], Step [2800/12500] Loss: 0.4586\n",
      "Epoch [6/80], Step [2900/12500] Loss: 0.6956\n",
      "Epoch [6/80], Step [3000/12500] Loss: 0.1139\n",
      "Epoch [6/80], Step [3100/12500] Loss: 0.7790\n",
      "Epoch [6/80], Step [3200/12500] Loss: 0.9114\n",
      "Epoch [6/80], Step [3300/12500] Loss: 1.3092\n",
      "Epoch [6/80], Step [3400/12500] Loss: 0.8352\n",
      "Epoch [6/80], Step [3500/12500] Loss: 0.3018\n",
      "Epoch [6/80], Step [3600/12500] Loss: 0.3677\n",
      "Epoch [6/80], Step [3700/12500] Loss: 0.0785\n",
      "Epoch [6/80], Step [3800/12500] Loss: 0.8768\n",
      "Epoch [6/80], Step [3900/12500] Loss: 0.2513\n",
      "Epoch [6/80], Step [4000/12500] Loss: 0.3376\n",
      "Epoch [6/80], Step [4100/12500] Loss: 2.2612\n",
      "Epoch [6/80], Step [4200/12500] Loss: 0.1053\n",
      "Epoch [6/80], Step [4300/12500] Loss: 0.3120\n",
      "Epoch [6/80], Step [4400/12500] Loss: 0.0740\n",
      "Epoch [6/80], Step [4500/12500] Loss: 1.9146\n",
      "Epoch [6/80], Step [4600/12500] Loss: 0.2660\n",
      "Epoch [6/80], Step [4700/12500] Loss: 0.1720\n",
      "Epoch [6/80], Step [4800/12500] Loss: 0.2788\n",
      "Epoch [6/80], Step [4900/12500] Loss: 0.5072\n",
      "Epoch [6/80], Step [5000/12500] Loss: 1.1656\n",
      "Epoch [6/80], Step [5100/12500] Loss: 1.5654\n",
      "Epoch [6/80], Step [5200/12500] Loss: 0.8902\n",
      "Epoch [6/80], Step [5300/12500] Loss: 0.5030\n",
      "Epoch [6/80], Step [5400/12500] Loss: 1.3393\n",
      "Epoch [6/80], Step [5500/12500] Loss: 0.9514\n",
      "Epoch [6/80], Step [5600/12500] Loss: 0.5506\n",
      "Epoch [6/80], Step [5700/12500] Loss: 0.1203\n",
      "Epoch [6/80], Step [5800/12500] Loss: 2.0828\n",
      "Epoch [6/80], Step [5900/12500] Loss: 0.5481\n",
      "Epoch [6/80], Step [6000/12500] Loss: 0.6558\n",
      "Epoch [6/80], Step [6100/12500] Loss: 0.0728\n",
      "Epoch [6/80], Step [6200/12500] Loss: 0.3683\n",
      "Epoch [6/80], Step [6300/12500] Loss: 0.4185\n",
      "Epoch [6/80], Step [6400/12500] Loss: 0.2286\n",
      "Epoch [6/80], Step [6500/12500] Loss: 0.7331\n",
      "Epoch [6/80], Step [6600/12500] Loss: 1.9734\n",
      "Epoch [6/80], Step [6700/12500] Loss: 0.0759\n",
      "Epoch [6/80], Step [6800/12500] Loss: 0.3163\n",
      "Epoch [6/80], Step [6900/12500] Loss: 0.6651\n",
      "Epoch [6/80], Step [7000/12500] Loss: 0.6187\n",
      "Epoch [6/80], Step [7100/12500] Loss: 0.1839\n",
      "Epoch [6/80], Step [7200/12500] Loss: 0.1097\n",
      "Epoch [6/80], Step [7300/12500] Loss: 0.8879\n",
      "Epoch [6/80], Step [7400/12500] Loss: 0.3764\n",
      "Epoch [6/80], Step [7500/12500] Loss: 0.1658\n",
      "Epoch [6/80], Step [7600/12500] Loss: 0.4156\n",
      "Epoch [6/80], Step [7700/12500] Loss: 0.7964\n",
      "Epoch [6/80], Step [7800/12500] Loss: 0.6395\n",
      "Epoch [6/80], Step [7900/12500] Loss: 0.2150\n",
      "Epoch [6/80], Step [8000/12500] Loss: 1.0092\n",
      "Epoch [6/80], Step [8100/12500] Loss: 1.1099\n",
      "Epoch [6/80], Step [8200/12500] Loss: 0.2648\n",
      "Epoch [6/80], Step [8300/12500] Loss: 0.2192\n",
      "Epoch [6/80], Step [8400/12500] Loss: 0.7883\n",
      "Epoch [6/80], Step [8500/12500] Loss: 0.3964\n",
      "Epoch [6/80], Step [8600/12500] Loss: 0.0966\n",
      "Epoch [6/80], Step [8700/12500] Loss: 0.1697\n",
      "Epoch [6/80], Step [8800/12500] Loss: 0.3746\n",
      "Epoch [6/80], Step [8900/12500] Loss: 0.1377\n",
      "Epoch [6/80], Step [9000/12500] Loss: 0.3276\n",
      "Epoch [6/80], Step [9100/12500] Loss: 1.0326\n",
      "Epoch [6/80], Step [9200/12500] Loss: 0.6580\n",
      "Epoch [6/80], Step [9300/12500] Loss: 0.5912\n",
      "Epoch [6/80], Step [9400/12500] Loss: 0.2574\n",
      "Epoch [6/80], Step [9500/12500] Loss: 0.3590\n",
      "Epoch [6/80], Step [9600/12500] Loss: 0.2634\n",
      "Epoch [6/80], Step [9700/12500] Loss: 0.4159\n",
      "Epoch [6/80], Step [9800/12500] Loss: 0.4956\n",
      "Epoch [6/80], Step [9900/12500] Loss: 0.5064\n",
      "Epoch [6/80], Step [10000/12500] Loss: 0.2491\n",
      "Epoch [6/80], Step [10100/12500] Loss: 0.8289\n",
      "Epoch [6/80], Step [10200/12500] Loss: 1.0733\n",
      "Epoch [6/80], Step [10300/12500] Loss: 0.8659\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/80], Step [10400/12500] Loss: 0.4092\n",
      "Epoch [6/80], Step [10500/12500] Loss: 0.1689\n",
      "Epoch [6/80], Step [10600/12500] Loss: 1.3556\n",
      "Epoch [6/80], Step [10700/12500] Loss: 0.2569\n",
      "Epoch [6/80], Step [10800/12500] Loss: 0.0457\n",
      "Epoch [6/80], Step [10900/12500] Loss: 0.2080\n",
      "Epoch [6/80], Step [11000/12500] Loss: 1.5791\n",
      "Epoch [6/80], Step [11100/12500] Loss: 0.9342\n",
      "Epoch [6/80], Step [11200/12500] Loss: 0.9940\n",
      "Epoch [6/80], Step [11300/12500] Loss: 0.0919\n",
      "Epoch [6/80], Step [11400/12500] Loss: 1.2279\n",
      "Epoch [6/80], Step [11500/12500] Loss: 0.5780\n",
      "Epoch [6/80], Step [11600/12500] Loss: 0.0578\n",
      "Epoch [6/80], Step [11700/12500] Loss: 0.0808\n",
      "Epoch [6/80], Step [11800/12500] Loss: 0.5510\n",
      "Epoch [6/80], Step [11900/12500] Loss: 0.2208\n",
      "Epoch [6/80], Step [12000/12500] Loss: 0.1342\n",
      "Epoch [6/80], Step [12100/12500] Loss: 0.8073\n",
      "Epoch [6/80], Step [12200/12500] Loss: 0.4103\n",
      "Epoch [6/80], Step [12300/12500] Loss: 0.3960\n",
      "Epoch [6/80], Step [12400/12500] Loss: 0.6809\n",
      "Epoch [6/80], Step [12500/12500] Loss: 0.1063\n",
      "Epoch [7/80], Step [100/12500] Loss: 0.2324\n",
      "Epoch [7/80], Step [200/12500] Loss: 0.2757\n",
      "Epoch [7/80], Step [300/12500] Loss: 0.1217\n",
      "Epoch [7/80], Step [400/12500] Loss: 0.1973\n",
      "Epoch [7/80], Step [500/12500] Loss: 0.3390\n",
      "Epoch [7/80], Step [600/12500] Loss: 0.7660\n",
      "Epoch [7/80], Step [700/12500] Loss: 0.1099\n",
      "Epoch [7/80], Step [800/12500] Loss: 0.4659\n",
      "Epoch [7/80], Step [900/12500] Loss: 0.2962\n",
      "Epoch [7/80], Step [1000/12500] Loss: 1.1774\n",
      "Epoch [7/80], Step [1100/12500] Loss: 0.6770\n",
      "Epoch [7/80], Step [1200/12500] Loss: 0.8872\n",
      "Epoch [7/80], Step [1300/12500] Loss: 0.4817\n",
      "Epoch [7/80], Step [1400/12500] Loss: 0.9329\n",
      "Epoch [7/80], Step [1500/12500] Loss: 0.3497\n",
      "Epoch [7/80], Step [1600/12500] Loss: 0.5462\n",
      "Epoch [7/80], Step [1700/12500] Loss: 0.0679\n",
      "Epoch [7/80], Step [1800/12500] Loss: 0.2513\n",
      "Epoch [7/80], Step [1900/12500] Loss: 1.0386\n",
      "Epoch [7/80], Step [2000/12500] Loss: 0.5304\n",
      "Epoch [7/80], Step [2100/12500] Loss: 0.8212\n",
      "Epoch [7/80], Step [2200/12500] Loss: 2.4082\n",
      "Epoch [7/80], Step [2300/12500] Loss: 1.7790\n",
      "Epoch [7/80], Step [2400/12500] Loss: 0.5958\n",
      "Epoch [7/80], Step [2500/12500] Loss: 0.4340\n",
      "Epoch [7/80], Step [2600/12500] Loss: 0.2419\n",
      "Epoch [7/80], Step [2700/12500] Loss: 0.4391\n",
      "Epoch [7/80], Step [2800/12500] Loss: 1.1686\n",
      "Epoch [7/80], Step [2900/12500] Loss: 0.3611\n",
      "Epoch [7/80], Step [3000/12500] Loss: 0.0700\n",
      "Epoch [7/80], Step [3100/12500] Loss: 0.0285\n",
      "Epoch [7/80], Step [3200/12500] Loss: 1.0605\n",
      "Epoch [7/80], Step [3300/12500] Loss: 0.4298\n",
      "Epoch [7/80], Step [3400/12500] Loss: 0.4703\n",
      "Epoch [7/80], Step [3500/12500] Loss: 1.3984\n",
      "Epoch [7/80], Step [3600/12500] Loss: 0.4248\n",
      "Epoch [7/80], Step [3700/12500] Loss: 0.5765\n",
      "Epoch [7/80], Step [3800/12500] Loss: 0.7980\n",
      "Epoch [7/80], Step [3900/12500] Loss: 0.9220\n",
      "Epoch [7/80], Step [4000/12500] Loss: 0.4256\n",
      "Epoch [7/80], Step [4100/12500] Loss: 1.9943\n",
      "Epoch [7/80], Step [4200/12500] Loss: 0.2396\n",
      "Epoch [7/80], Step [4300/12500] Loss: 3.5234\n",
      "Epoch [7/80], Step [4400/12500] Loss: 0.4614\n",
      "Epoch [7/80], Step [4500/12500] Loss: 0.2093\n",
      "Epoch [7/80], Step [4600/12500] Loss: 0.2423\n",
      "Epoch [7/80], Step [4700/12500] Loss: 0.2274\n",
      "Epoch [7/80], Step [4800/12500] Loss: 0.1486\n",
      "Epoch [7/80], Step [4900/12500] Loss: 1.5234\n",
      "Epoch [7/80], Step [5000/12500] Loss: 1.5068\n",
      "Epoch [7/80], Step [5100/12500] Loss: 1.3461\n",
      "Epoch [7/80], Step [5200/12500] Loss: 1.0615\n",
      "Epoch [7/80], Step [5300/12500] Loss: 0.2652\n",
      "Epoch [7/80], Step [5400/12500] Loss: 0.2314\n",
      "Epoch [7/80], Step [5500/12500] Loss: 0.1817\n",
      "Epoch [7/80], Step [5600/12500] Loss: 0.2458\n",
      "Epoch [7/80], Step [5700/12500] Loss: 0.6945\n",
      "Epoch [7/80], Step [5800/12500] Loss: 0.1578\n",
      "Epoch [7/80], Step [5900/12500] Loss: 0.2761\n",
      "Epoch [7/80], Step [6000/12500] Loss: 1.4075\n",
      "Epoch [7/80], Step [6100/12500] Loss: 0.5374\n",
      "Epoch [7/80], Step [6200/12500] Loss: 0.2730\n",
      "Epoch [7/80], Step [6300/12500] Loss: 0.4606\n",
      "Epoch [7/80], Step [6400/12500] Loss: 0.6112\n",
      "Epoch [7/80], Step [6500/12500] Loss: 0.8672\n",
      "Epoch [7/80], Step [6600/12500] Loss: 1.3405\n",
      "Epoch [7/80], Step [6700/12500] Loss: 0.4143\n",
      "Epoch [7/80], Step [6800/12500] Loss: 0.0370\n",
      "Epoch [7/80], Step [6900/12500] Loss: 1.6335\n",
      "Epoch [7/80], Step [7000/12500] Loss: 0.5494\n",
      "Epoch [7/80], Step [7100/12500] Loss: 0.1717\n",
      "Epoch [7/80], Step [7200/12500] Loss: 0.6483\n",
      "Epoch [7/80], Step [7300/12500] Loss: 0.5559\n",
      "Epoch [7/80], Step [7400/12500] Loss: 1.1839\n",
      "Epoch [7/80], Step [7500/12500] Loss: 0.3519\n",
      "Epoch [7/80], Step [7600/12500] Loss: 1.0854\n",
      "Epoch [7/80], Step [7700/12500] Loss: 0.9832\n",
      "Epoch [7/80], Step [7800/12500] Loss: 0.8042\n",
      "Epoch [7/80], Step [7900/12500] Loss: 0.2681\n",
      "Epoch [7/80], Step [8000/12500] Loss: 0.1675\n",
      "Epoch [7/80], Step [8100/12500] Loss: 0.3026\n",
      "Epoch [7/80], Step [8200/12500] Loss: 0.1333\n",
      "Epoch [7/80], Step [8300/12500] Loss: 0.2740\n",
      "Epoch [7/80], Step [8400/12500] Loss: 1.0328\n",
      "Epoch [7/80], Step [8500/12500] Loss: 0.3583\n",
      "Epoch [7/80], Step [8600/12500] Loss: 1.1940\n",
      "Epoch [7/80], Step [8700/12500] Loss: 0.0862\n",
      "Epoch [7/80], Step [8800/12500] Loss: 1.1332\n",
      "Epoch [7/80], Step [8900/12500] Loss: 0.9293\n",
      "Epoch [7/80], Step [9000/12500] Loss: 1.1299\n",
      "Epoch [7/80], Step [9100/12500] Loss: 0.2935\n",
      "Epoch [7/80], Step [9200/12500] Loss: 0.5831\n",
      "Epoch [7/80], Step [9300/12500] Loss: 0.7067\n",
      "Epoch [7/80], Step [9400/12500] Loss: 0.5185\n",
      "Epoch [7/80], Step [9500/12500] Loss: 0.4681\n",
      "Epoch [7/80], Step [9600/12500] Loss: 0.3419\n",
      "Epoch [7/80], Step [9700/12500] Loss: 1.0603\n",
      "Epoch [7/80], Step [9800/12500] Loss: 0.5535\n",
      "Epoch [7/80], Step [9900/12500] Loss: 0.2351\n",
      "Epoch [7/80], Step [10000/12500] Loss: 0.1837\n",
      "Epoch [7/80], Step [10100/12500] Loss: 1.3350\n",
      "Epoch [7/80], Step [10200/12500] Loss: 0.1275\n",
      "Epoch [7/80], Step [10300/12500] Loss: 1.4544\n",
      "Epoch [7/80], Step [10400/12500] Loss: 0.2838\n",
      "Epoch [7/80], Step [10500/12500] Loss: 1.4987\n",
      "Epoch [7/80], Step [10600/12500] Loss: 0.2397\n",
      "Epoch [7/80], Step [10700/12500] Loss: 0.2142\n",
      "Epoch [7/80], Step [10800/12500] Loss: 0.1047\n",
      "Epoch [7/80], Step [10900/12500] Loss: 0.8398\n",
      "Epoch [7/80], Step [11000/12500] Loss: 0.7027\n",
      "Epoch [7/80], Step [11100/12500] Loss: 0.5356\n",
      "Epoch [7/80], Step [11200/12500] Loss: 0.6477\n",
      "Epoch [7/80], Step [11300/12500] Loss: 0.4198\n",
      "Epoch [7/80], Step [11400/12500] Loss: 0.9383\n",
      "Epoch [7/80], Step [11500/12500] Loss: 0.1238\n",
      "Epoch [7/80], Step [11600/12500] Loss: 0.1652\n",
      "Epoch [7/80], Step [11700/12500] Loss: 1.1686\n",
      "Epoch [7/80], Step [11800/12500] Loss: 0.6323\n",
      "Epoch [7/80], Step [11900/12500] Loss: 0.5066\n",
      "Epoch [7/80], Step [12000/12500] Loss: 0.3748\n",
      "Epoch [7/80], Step [12100/12500] Loss: 0.3830\n",
      "Epoch [7/80], Step [12200/12500] Loss: 0.1377\n",
      "Epoch [7/80], Step [12300/12500] Loss: 0.8001\n",
      "Epoch [7/80], Step [12400/12500] Loss: 0.4208\n",
      "Epoch [7/80], Step [12500/12500] Loss: 0.7753\n",
      "Epoch [8/80], Step [100/12500] Loss: 0.3695\n",
      "Epoch [8/80], Step [200/12500] Loss: 0.8497\n",
      "Epoch [8/80], Step [300/12500] Loss: 0.3191\n",
      "Epoch [8/80], Step [400/12500] Loss: 1.0678\n",
      "Epoch [8/80], Step [500/12500] Loss: 0.1953\n",
      "Epoch [8/80], Step [600/12500] Loss: 1.2127\n",
      "Epoch [8/80], Step [700/12500] Loss: 0.4531\n",
      "Epoch [8/80], Step [800/12500] Loss: 1.0767\n",
      "Epoch [8/80], Step [900/12500] Loss: 0.1657\n",
      "Epoch [8/80], Step [1000/12500] Loss: 0.0719\n",
      "Epoch [8/80], Step [1100/12500] Loss: 0.7692\n",
      "Epoch [8/80], Step [1200/12500] Loss: 0.1907\n",
      "Epoch [8/80], Step [1300/12500] Loss: 0.8058\n",
      "Epoch [8/80], Step [1400/12500] Loss: 0.8179\n",
      "Epoch [8/80], Step [1500/12500] Loss: 1.3326\n",
      "Epoch [8/80], Step [1600/12500] Loss: 0.0925\n",
      "Epoch [8/80], Step [1700/12500] Loss: 0.0597\n",
      "Epoch [8/80], Step [1800/12500] Loss: 1.7027\n",
      "Epoch [8/80], Step [1900/12500] Loss: 0.3674\n",
      "Epoch [8/80], Step [2000/12500] Loss: 0.9972\n",
      "Epoch [8/80], Step [2100/12500] Loss: 1.0519\n",
      "Epoch [8/80], Step [2200/12500] Loss: 0.4540\n",
      "Epoch [8/80], Step [2300/12500] Loss: 0.5960\n",
      "Epoch [8/80], Step [2400/12500] Loss: 0.3404\n",
      "Epoch [8/80], Step [2500/12500] Loss: 0.1468\n",
      "Epoch [8/80], Step [2600/12500] Loss: 1.0879\n",
      "Epoch [8/80], Step [2700/12500] Loss: 0.8614\n",
      "Epoch [8/80], Step [2800/12500] Loss: 1.1367\n",
      "Epoch [8/80], Step [2900/12500] Loss: 0.1617\n",
      "Epoch [8/80], Step [3000/12500] Loss: 0.9897\n",
      "Epoch [8/80], Step [3100/12500] Loss: 1.3389\n",
      "Epoch [8/80], Step [3200/12500] Loss: 0.3224\n",
      "Epoch [8/80], Step [3300/12500] Loss: 0.8011\n",
      "Epoch [8/80], Step [3400/12500] Loss: 0.4684\n",
      "Epoch [8/80], Step [3500/12500] Loss: 0.0706\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/80], Step [3600/12500] Loss: 0.2525\n",
      "Epoch [8/80], Step [3700/12500] Loss: 1.4601\n",
      "Epoch [8/80], Step [3800/12500] Loss: 0.2022\n",
      "Epoch [8/80], Step [3900/12500] Loss: 0.2024\n",
      "Epoch [8/80], Step [4000/12500] Loss: 0.1160\n",
      "Epoch [8/80], Step [4100/12500] Loss: 0.4743\n",
      "Epoch [8/80], Step [4200/12500] Loss: 0.1036\n",
      "Epoch [8/80], Step [4300/12500] Loss: 0.1825\n",
      "Epoch [8/80], Step [4400/12500] Loss: 0.0943\n",
      "Epoch [8/80], Step [4500/12500] Loss: 0.0289\n",
      "Epoch [8/80], Step [4600/12500] Loss: 0.2133\n",
      "Epoch [8/80], Step [4700/12500] Loss: 0.4588\n",
      "Epoch [8/80], Step [4800/12500] Loss: 0.3297\n",
      "Epoch [8/80], Step [4900/12500] Loss: 1.0723\n",
      "Epoch [8/80], Step [5000/12500] Loss: 0.2229\n",
      "Epoch [8/80], Step [5100/12500] Loss: 1.6734\n",
      "Epoch [8/80], Step [5200/12500] Loss: 0.5132\n",
      "Epoch [8/80], Step [5300/12500] Loss: 0.0894\n",
      "Epoch [8/80], Step [5400/12500] Loss: 0.1231\n",
      "Epoch [8/80], Step [5500/12500] Loss: 0.4787\n",
      "Epoch [8/80], Step [5600/12500] Loss: 0.8134\n",
      "Epoch [8/80], Step [5700/12500] Loss: 0.0565\n",
      "Epoch [8/80], Step [5800/12500] Loss: 0.8171\n",
      "Epoch [8/80], Step [5900/12500] Loss: 0.4635\n",
      "Epoch [8/80], Step [6000/12500] Loss: 0.9787\n",
      "Epoch [8/80], Step [6100/12500] Loss: 0.0840\n",
      "Epoch [8/80], Step [6200/12500] Loss: 0.9074\n",
      "Epoch [8/80], Step [6300/12500] Loss: 0.9202\n",
      "Epoch [8/80], Step [6400/12500] Loss: 0.3887\n",
      "Epoch [8/80], Step [6500/12500] Loss: 0.0788\n",
      "Epoch [8/80], Step [6600/12500] Loss: 0.6321\n",
      "Epoch [8/80], Step [6700/12500] Loss: 1.7707\n",
      "Epoch [8/80], Step [6800/12500] Loss: 1.1863\n",
      "Epoch [8/80], Step [6900/12500] Loss: 0.3008\n",
      "Epoch [8/80], Step [7000/12500] Loss: 0.4097\n",
      "Epoch [8/80], Step [7100/12500] Loss: 0.4693\n",
      "Epoch [8/80], Step [7200/12500] Loss: 0.2294\n",
      "Epoch [8/80], Step [7300/12500] Loss: 0.2873\n",
      "Epoch [8/80], Step [7400/12500] Loss: 0.4351\n",
      "Epoch [8/80], Step [7500/12500] Loss: 0.3346\n",
      "Epoch [8/80], Step [7600/12500] Loss: 0.0824\n",
      "Epoch [8/80], Step [7700/12500] Loss: 1.0544\n",
      "Epoch [8/80], Step [7800/12500] Loss: 1.4650\n",
      "Epoch [8/80], Step [7900/12500] Loss: 0.8370\n",
      "Epoch [8/80], Step [8000/12500] Loss: 0.8856\n",
      "Epoch [8/80], Step [8100/12500] Loss: 0.3464\n",
      "Epoch [8/80], Step [8200/12500] Loss: 0.3389\n",
      "Epoch [8/80], Step [8300/12500] Loss: 0.6988\n",
      "Epoch [8/80], Step [8400/12500] Loss: 0.1616\n",
      "Epoch [8/80], Step [8500/12500] Loss: 0.8699\n",
      "Epoch [8/80], Step [8600/12500] Loss: 1.9036\n",
      "Epoch [8/80], Step [8700/12500] Loss: 0.5948\n",
      "Epoch [8/80], Step [8800/12500] Loss: 1.8188\n",
      "Epoch [8/80], Step [8900/12500] Loss: 0.6784\n",
      "Epoch [8/80], Step [9000/12500] Loss: 0.9172\n",
      "Epoch [8/80], Step [9100/12500] Loss: 0.2027\n",
      "Epoch [8/80], Step [9200/12500] Loss: 0.5257\n",
      "Epoch [8/80], Step [9300/12500] Loss: 0.1418\n",
      "Epoch [8/80], Step [9400/12500] Loss: 1.1066\n",
      "Epoch [8/80], Step [9500/12500] Loss: 0.1623\n",
      "Epoch [8/80], Step [9600/12500] Loss: 0.1241\n",
      "Epoch [8/80], Step [9700/12500] Loss: 0.5719\n",
      "Epoch [8/80], Step [9800/12500] Loss: 0.9283\n",
      "Epoch [8/80], Step [9900/12500] Loss: 0.1750\n",
      "Epoch [8/80], Step [10000/12500] Loss: 0.2882\n",
      "Epoch [8/80], Step [10100/12500] Loss: 0.4464\n",
      "Epoch [8/80], Step [10200/12500] Loss: 1.1773\n",
      "Epoch [8/80], Step [10300/12500] Loss: 0.0477\n",
      "Epoch [8/80], Step [10400/12500] Loss: 0.2751\n",
      "Epoch [8/80], Step [10500/12500] Loss: 1.5513\n",
      "Epoch [8/80], Step [10600/12500] Loss: 0.3151\n",
      "Epoch [8/80], Step [10700/12500] Loss: 0.3962\n",
      "Epoch [8/80], Step [10800/12500] Loss: 0.1895\n",
      "Epoch [8/80], Step [10900/12500] Loss: 0.6582\n",
      "Epoch [8/80], Step [11000/12500] Loss: 1.0130\n",
      "Epoch [8/80], Step [11100/12500] Loss: 0.2925\n",
      "Epoch [8/80], Step [11200/12500] Loss: 0.3347\n",
      "Epoch [8/80], Step [11300/12500] Loss: 0.1252\n",
      "Epoch [8/80], Step [11400/12500] Loss: 0.8492\n",
      "Epoch [8/80], Step [11500/12500] Loss: 0.6524\n",
      "Epoch [8/80], Step [11600/12500] Loss: 0.1723\n",
      "Epoch [8/80], Step [11700/12500] Loss: 0.8851\n",
      "Epoch [8/80], Step [11800/12500] Loss: 0.2521\n",
      "Epoch [8/80], Step [11900/12500] Loss: 0.2222\n",
      "Epoch [8/80], Step [12000/12500] Loss: 0.8006\n",
      "Epoch [8/80], Step [12100/12500] Loss: 0.6053\n",
      "Epoch [8/80], Step [12200/12500] Loss: 0.4635\n",
      "Epoch [8/80], Step [12300/12500] Loss: 0.6162\n",
      "Epoch [8/80], Step [12400/12500] Loss: 0.6273\n",
      "Epoch [8/80], Step [12500/12500] Loss: 0.2443\n",
      "Epoch [9/80], Step [100/12500] Loss: 0.0614\n",
      "Epoch [9/80], Step [200/12500] Loss: 0.6831\n",
      "Epoch [9/80], Step [300/12500] Loss: 1.0600\n",
      "Epoch [9/80], Step [400/12500] Loss: 0.2586\n",
      "Epoch [9/80], Step [500/12500] Loss: 0.6321\n",
      "Epoch [9/80], Step [600/12500] Loss: 0.1355\n",
      "Epoch [9/80], Step [700/12500] Loss: 1.0677\n",
      "Epoch [9/80], Step [800/12500] Loss: 1.0091\n",
      "Epoch [9/80], Step [900/12500] Loss: 0.0439\n",
      "Epoch [9/80], Step [1000/12500] Loss: 0.7268\n",
      "Epoch [9/80], Step [1100/12500] Loss: 2.6841\n",
      "Epoch [9/80], Step [1200/12500] Loss: 0.5080\n",
      "Epoch [9/80], Step [1300/12500] Loss: 0.1550\n",
      "Epoch [9/80], Step [1400/12500] Loss: 0.3730\n",
      "Epoch [9/80], Step [1500/12500] Loss: 0.0641\n",
      "Epoch [9/80], Step [1600/12500] Loss: 0.0501\n",
      "Epoch [9/80], Step [1700/12500] Loss: 0.7576\n",
      "Epoch [9/80], Step [1800/12500] Loss: 0.8300\n",
      "Epoch [9/80], Step [1900/12500] Loss: 0.1200\n",
      "Epoch [9/80], Step [2000/12500] Loss: 1.0694\n",
      "Epoch [9/80], Step [2100/12500] Loss: 0.6476\n",
      "Epoch [9/80], Step [2200/12500] Loss: 0.9653\n",
      "Epoch [9/80], Step [2300/12500] Loss: 0.4591\n",
      "Epoch [9/80], Step [2400/12500] Loss: 1.3368\n",
      "Epoch [9/80], Step [2500/12500] Loss: 0.2123\n",
      "Epoch [9/80], Step [2600/12500] Loss: 1.2721\n",
      "Epoch [9/80], Step [2700/12500] Loss: 0.1275\n",
      "Epoch [9/80], Step [2800/12500] Loss: 0.1262\n",
      "Epoch [9/80], Step [2900/12500] Loss: 0.8796\n",
      "Epoch [9/80], Step [3000/12500] Loss: 0.0361\n",
      "Epoch [9/80], Step [3100/12500] Loss: 0.0922\n",
      "Epoch [9/80], Step [3200/12500] Loss: 1.9485\n",
      "Epoch [9/80], Step [3300/12500] Loss: 1.2190\n",
      "Epoch [9/80], Step [3400/12500] Loss: 0.3649\n",
      "Epoch [9/80], Step [3500/12500] Loss: 0.4426\n",
      "Epoch [9/80], Step [3600/12500] Loss: 0.7881\n",
      "Epoch [9/80], Step [3700/12500] Loss: 0.2151\n",
      "Epoch [9/80], Step [3800/12500] Loss: 0.4157\n",
      "Epoch [9/80], Step [3900/12500] Loss: 0.2218\n",
      "Epoch [9/80], Step [4000/12500] Loss: 0.3544\n",
      "Epoch [9/80], Step [4100/12500] Loss: 0.0413\n",
      "Epoch [9/80], Step [4200/12500] Loss: 0.3164\n",
      "Epoch [9/80], Step [4300/12500] Loss: 0.5243\n",
      "Epoch [9/80], Step [4400/12500] Loss: 1.3278\n",
      "Epoch [9/80], Step [4500/12500] Loss: 0.0514\n",
      "Epoch [9/80], Step [4600/12500] Loss: 0.1700\n",
      "Epoch [9/80], Step [4700/12500] Loss: 0.1726\n",
      "Epoch [9/80], Step [4800/12500] Loss: 0.0902\n",
      "Epoch [9/80], Step [4900/12500] Loss: 0.6386\n",
      "Epoch [9/80], Step [5000/12500] Loss: 0.1525\n",
      "Epoch [9/80], Step [5100/12500] Loss: 0.3887\n",
      "Epoch [9/80], Step [5200/12500] Loss: 0.0594\n",
      "Epoch [9/80], Step [5300/12500] Loss: 0.3501\n",
      "Epoch [9/80], Step [5400/12500] Loss: 0.2111\n",
      "Epoch [9/80], Step [5500/12500] Loss: 0.2848\n",
      "Epoch [9/80], Step [5600/12500] Loss: 0.7358\n",
      "Epoch [9/80], Step [5700/12500] Loss: 0.1661\n",
      "Epoch [9/80], Step [5800/12500] Loss: 0.3642\n",
      "Epoch [9/80], Step [5900/12500] Loss: 0.3407\n",
      "Epoch [9/80], Step [6000/12500] Loss: 1.6954\n",
      "Epoch [9/80], Step [6100/12500] Loss: 0.8128\n",
      "Epoch [9/80], Step [6200/12500] Loss: 0.2257\n",
      "Epoch [9/80], Step [6300/12500] Loss: 0.8252\n",
      "Epoch [9/80], Step [6400/12500] Loss: 0.1813\n",
      "Epoch [9/80], Step [6500/12500] Loss: 0.0966\n",
      "Epoch [9/80], Step [6600/12500] Loss: 0.3925\n",
      "Epoch [9/80], Step [6700/12500] Loss: 0.2944\n",
      "Epoch [9/80], Step [6800/12500] Loss: 0.3560\n",
      "Epoch [9/80], Step [6900/12500] Loss: 0.1750\n",
      "Epoch [9/80], Step [7000/12500] Loss: 0.3790\n",
      "Epoch [9/80], Step [7100/12500] Loss: 0.6109\n",
      "Epoch [9/80], Step [7200/12500] Loss: 0.0921\n",
      "Epoch [9/80], Step [7300/12500] Loss: 0.2835\n",
      "Epoch [9/80], Step [7400/12500] Loss: 0.4960\n",
      "Epoch [9/80], Step [7500/12500] Loss: 0.1582\n",
      "Epoch [9/80], Step [7600/12500] Loss: 1.4902\n",
      "Epoch [9/80], Step [7700/12500] Loss: 0.6190\n",
      "Epoch [9/80], Step [7800/12500] Loss: 0.2660\n",
      "Epoch [9/80], Step [7900/12500] Loss: 0.7121\n",
      "Epoch [9/80], Step [8000/12500] Loss: 0.1662\n",
      "Epoch [9/80], Step [8100/12500] Loss: 0.4084\n",
      "Epoch [9/80], Step [8200/12500] Loss: 0.0585\n",
      "Epoch [9/80], Step [8300/12500] Loss: 0.1893\n",
      "Epoch [9/80], Step [8400/12500] Loss: 0.5115\n",
      "Epoch [9/80], Step [8500/12500] Loss: 0.1476\n",
      "Epoch [9/80], Step [8600/12500] Loss: 0.8195\n",
      "Epoch [9/80], Step [8700/12500] Loss: 0.5846\n",
      "Epoch [9/80], Step [8800/12500] Loss: 0.4019\n",
      "Epoch [9/80], Step [8900/12500] Loss: 0.2916\n",
      "Epoch [9/80], Step [9000/12500] Loss: 0.1884\n",
      "Epoch [9/80], Step [9100/12500] Loss: 1.0787\n",
      "Epoch [9/80], Step [9200/12500] Loss: 0.9675\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/80], Step [9300/12500] Loss: 1.0339\n",
      "Epoch [9/80], Step [9400/12500] Loss: 1.4647\n",
      "Epoch [9/80], Step [9500/12500] Loss: 1.0274\n",
      "Epoch [9/80], Step [9600/12500] Loss: 0.2850\n",
      "Epoch [9/80], Step [9700/12500] Loss: 0.1404\n",
      "Epoch [9/80], Step [9800/12500] Loss: 0.4876\n",
      "Epoch [9/80], Step [9900/12500] Loss: 0.9819\n",
      "Epoch [9/80], Step [10000/12500] Loss: 1.1593\n",
      "Epoch [9/80], Step [10100/12500] Loss: 0.2048\n",
      "Epoch [9/80], Step [10200/12500] Loss: 1.0433\n",
      "Epoch [9/80], Step [10300/12500] Loss: 0.2462\n",
      "Epoch [9/80], Step [10400/12500] Loss: 0.0428\n",
      "Epoch [9/80], Step [10500/12500] Loss: 1.0207\n",
      "Epoch [9/80], Step [10600/12500] Loss: 0.4135\n",
      "Epoch [9/80], Step [10700/12500] Loss: 0.5074\n",
      "Epoch [9/80], Step [10800/12500] Loss: 0.4754\n",
      "Epoch [9/80], Step [10900/12500] Loss: 0.2581\n",
      "Epoch [9/80], Step [11000/12500] Loss: 0.6277\n",
      "Epoch [9/80], Step [11100/12500] Loss: 0.1720\n",
      "Epoch [9/80], Step [11200/12500] Loss: 0.0170\n",
      "Epoch [9/80], Step [11300/12500] Loss: 0.2595\n",
      "Epoch [9/80], Step [11400/12500] Loss: 0.2228\n",
      "Epoch [9/80], Step [11500/12500] Loss: 0.7604\n",
      "Epoch [9/80], Step [11600/12500] Loss: 0.5661\n",
      "Epoch [9/80], Step [11700/12500] Loss: 0.8198\n",
      "Epoch [9/80], Step [11800/12500] Loss: 0.5481\n",
      "Epoch [9/80], Step [11900/12500] Loss: 0.1986\n",
      "Epoch [9/80], Step [12000/12500] Loss: 0.1057\n",
      "Epoch [9/80], Step [12100/12500] Loss: 0.4894\n",
      "Epoch [9/80], Step [12200/12500] Loss: 0.4288\n",
      "Epoch [9/80], Step [12300/12500] Loss: 0.1426\n",
      "Epoch [9/80], Step [12400/12500] Loss: 0.6243\n",
      "Epoch [9/80], Step [12500/12500] Loss: 0.1273\n",
      "Epoch [10/80], Step [100/12500] Loss: 1.2082\n",
      "Epoch [10/80], Step [200/12500] Loss: 0.1500\n",
      "Epoch [10/80], Step [300/12500] Loss: 0.2683\n",
      "Epoch [10/80], Step [400/12500] Loss: 0.1998\n",
      "Epoch [10/80], Step [500/12500] Loss: 1.8839\n",
      "Epoch [10/80], Step [600/12500] Loss: 1.0916\n",
      "Epoch [10/80], Step [700/12500] Loss: 0.5575\n",
      "Epoch [10/80], Step [800/12500] Loss: 0.0978\n",
      "Epoch [10/80], Step [900/12500] Loss: 0.1273\n",
      "Epoch [10/80], Step [1000/12500] Loss: 0.7154\n",
      "Epoch [10/80], Step [1100/12500] Loss: 0.7471\n",
      "Epoch [10/80], Step [1200/12500] Loss: 0.4226\n",
      "Epoch [10/80], Step [1300/12500] Loss: 0.2546\n",
      "Epoch [10/80], Step [1400/12500] Loss: 2.3477\n",
      "Epoch [10/80], Step [1500/12500] Loss: 0.7713\n",
      "Epoch [10/80], Step [1600/12500] Loss: 0.4918\n",
      "Epoch [10/80], Step [1700/12500] Loss: 1.2857\n",
      "Epoch [10/80], Step [1800/12500] Loss: 0.1735\n",
      "Epoch [10/80], Step [1900/12500] Loss: 0.6833\n",
      "Epoch [10/80], Step [2000/12500] Loss: 1.5188\n",
      "Epoch [10/80], Step [2100/12500] Loss: 0.1103\n",
      "Epoch [10/80], Step [2200/12500] Loss: 0.0962\n",
      "Epoch [10/80], Step [2300/12500] Loss: 0.2913\n",
      "Epoch [10/80], Step [2400/12500] Loss: 0.1201\n",
      "Epoch [10/80], Step [2500/12500] Loss: 0.6980\n",
      "Epoch [10/80], Step [2600/12500] Loss: 0.2768\n",
      "Epoch [10/80], Step [2700/12500] Loss: 0.1087\n",
      "Epoch [10/80], Step [2800/12500] Loss: 0.2557\n",
      "Epoch [10/80], Step [2900/12500] Loss: 0.1460\n",
      "Epoch [10/80], Step [3000/12500] Loss: 1.3410\n",
      "Epoch [10/80], Step [3100/12500] Loss: 0.0904\n",
      "Epoch [10/80], Step [3200/12500] Loss: 0.4806\n",
      "Epoch [10/80], Step [3300/12500] Loss: 1.3444\n",
      "Epoch [10/80], Step [3400/12500] Loss: 1.7633\n",
      "Epoch [10/80], Step [3500/12500] Loss: 0.1535\n",
      "Epoch [10/80], Step [3600/12500] Loss: 0.0330\n",
      "Epoch [10/80], Step [3700/12500] Loss: 0.1949\n",
      "Epoch [10/80], Step [3800/12500] Loss: 0.0626\n",
      "Epoch [10/80], Step [3900/12500] Loss: 0.5885\n",
      "Epoch [10/80], Step [4000/12500] Loss: 0.0410\n",
      "Epoch [10/80], Step [4100/12500] Loss: 0.0372\n",
      "Epoch [10/80], Step [4200/12500] Loss: 1.0924\n",
      "Epoch [10/80], Step [4300/12500] Loss: 0.0212\n",
      "Epoch [10/80], Step [4400/12500] Loss: 0.2936\n",
      "Epoch [10/80], Step [4500/12500] Loss: 0.0327\n",
      "Epoch [10/80], Step [4600/12500] Loss: 0.0910\n",
      "Epoch [10/80], Step [4700/12500] Loss: 1.7560\n",
      "Epoch [10/80], Step [4800/12500] Loss: 0.2684\n",
      "Epoch [10/80], Step [4900/12500] Loss: 0.5699\n",
      "Epoch [10/80], Step [5000/12500] Loss: 0.1247\n",
      "Epoch [10/80], Step [5100/12500] Loss: 0.6599\n",
      "Epoch [10/80], Step [5200/12500] Loss: 0.5812\n",
      "Epoch [10/80], Step [5300/12500] Loss: 1.3630\n",
      "Epoch [10/80], Step [5400/12500] Loss: 0.4455\n",
      "Epoch [10/80], Step [5500/12500] Loss: 0.1722\n",
      "Epoch [10/80], Step [5600/12500] Loss: 1.0925\n",
      "Epoch [10/80], Step [5700/12500] Loss: 0.0757\n",
      "Epoch [10/80], Step [5800/12500] Loss: 1.5713\n",
      "Epoch [10/80], Step [5900/12500] Loss: 0.0515\n",
      "Epoch [10/80], Step [6000/12500] Loss: 0.0635\n",
      "Epoch [10/80], Step [6100/12500] Loss: 0.1810\n",
      "Epoch [10/80], Step [6200/12500] Loss: 0.5160\n",
      "Epoch [10/80], Step [6300/12500] Loss: 0.5021\n",
      "Epoch [10/80], Step [6400/12500] Loss: 0.4541\n",
      "Epoch [10/80], Step [6500/12500] Loss: 0.6516\n",
      "Epoch [10/80], Step [6600/12500] Loss: 0.1372\n",
      "Epoch [10/80], Step [6700/12500] Loss: 0.1225\n",
      "Epoch [10/80], Step [6800/12500] Loss: 0.0817\n",
      "Epoch [10/80], Step [6900/12500] Loss: 0.1007\n",
      "Epoch [10/80], Step [7000/12500] Loss: 0.2286\n",
      "Epoch [10/80], Step [7100/12500] Loss: 0.2894\n",
      "Epoch [10/80], Step [7200/12500] Loss: 0.1465\n",
      "Epoch [10/80], Step [7300/12500] Loss: 0.0989\n",
      "Epoch [10/80], Step [7400/12500] Loss: 0.4578\n",
      "Epoch [10/80], Step [7500/12500] Loss: 0.7167\n",
      "Epoch [10/80], Step [7600/12500] Loss: 0.0918\n",
      "Epoch [10/80], Step [7700/12500] Loss: 0.1282\n",
      "Epoch [10/80], Step [7800/12500] Loss: 1.0149\n",
      "Epoch [10/80], Step [7900/12500] Loss: 0.1803\n",
      "Epoch [10/80], Step [8000/12500] Loss: 1.0766\n",
      "Epoch [10/80], Step [8100/12500] Loss: 0.3481\n",
      "Epoch [10/80], Step [8200/12500] Loss: 0.2422\n",
      "Epoch [10/80], Step [8300/12500] Loss: 0.3820\n",
      "Epoch [10/80], Step [8400/12500] Loss: 1.0735\n",
      "Epoch [10/80], Step [8500/12500] Loss: 0.7278\n",
      "Epoch [10/80], Step [8600/12500] Loss: 0.6314\n",
      "Epoch [10/80], Step [8700/12500] Loss: 0.0097\n",
      "Epoch [10/80], Step [8800/12500] Loss: 1.9011\n",
      "Epoch [10/80], Step [8900/12500] Loss: 0.8915\n",
      "Epoch [10/80], Step [9000/12500] Loss: 0.3718\n",
      "Epoch [10/80], Step [9100/12500] Loss: 0.7778\n",
      "Epoch [10/80], Step [9200/12500] Loss: 0.0645\n",
      "Epoch [10/80], Step [9300/12500] Loss: 0.3501\n",
      "Epoch [10/80], Step [9400/12500] Loss: 0.0373\n",
      "Epoch [10/80], Step [9500/12500] Loss: 0.2969\n",
      "Epoch [10/80], Step [9600/12500] Loss: 0.1029\n",
      "Epoch [10/80], Step [9700/12500] Loss: 0.6327\n",
      "Epoch [10/80], Step [9800/12500] Loss: 0.8111\n",
      "Epoch [10/80], Step [9900/12500] Loss: 1.2349\n",
      "Epoch [10/80], Step [10000/12500] Loss: 0.1486\n",
      "Epoch [10/80], Step [10100/12500] Loss: 0.9959\n",
      "Epoch [10/80], Step [10200/12500] Loss: 0.0357\n",
      "Epoch [10/80], Step [10300/12500] Loss: 0.4874\n",
      "Epoch [10/80], Step [10400/12500] Loss: 0.3610\n",
      "Epoch [10/80], Step [10500/12500] Loss: 1.0572\n",
      "Epoch [10/80], Step [10600/12500] Loss: 0.4796\n",
      "Epoch [10/80], Step [10700/12500] Loss: 0.0040\n",
      "Epoch [10/80], Step [10800/12500] Loss: 0.0891\n",
      "Epoch [10/80], Step [10900/12500] Loss: 0.4065\n",
      "Epoch [10/80], Step [11000/12500] Loss: 0.7666\n",
      "Epoch [10/80], Step [11100/12500] Loss: 1.3898\n",
      "Epoch [10/80], Step [11200/12500] Loss: 0.4244\n",
      "Epoch [10/80], Step [11300/12500] Loss: 0.1371\n",
      "Epoch [10/80], Step [11400/12500] Loss: 0.9621\n",
      "Epoch [10/80], Step [11500/12500] Loss: 0.8404\n",
      "Epoch [10/80], Step [11600/12500] Loss: 0.5199\n",
      "Epoch [10/80], Step [11700/12500] Loss: 0.1771\n",
      "Epoch [10/80], Step [11800/12500] Loss: 0.9299\n",
      "Epoch [10/80], Step [11900/12500] Loss: 0.2212\n",
      "Epoch [10/80], Step [12000/12500] Loss: 0.3536\n",
      "Epoch [10/80], Step [12100/12500] Loss: 0.1104\n",
      "Epoch [10/80], Step [12200/12500] Loss: 0.4354\n",
      "Epoch [10/80], Step [12300/12500] Loss: 0.0787\n",
      "Epoch [10/80], Step [12400/12500] Loss: 0.3065\n",
      "Epoch [10/80], Step [12500/12500] Loss: 0.2062\n",
      "Epoch [11/80], Step [100/12500] Loss: 0.3552\n",
      "Epoch [11/80], Step [200/12500] Loss: 0.8368\n",
      "Epoch [11/80], Step [300/12500] Loss: 0.0208\n",
      "Epoch [11/80], Step [400/12500] Loss: 0.6725\n",
      "Epoch [11/80], Step [500/12500] Loss: 1.0947\n",
      "Epoch [11/80], Step [600/12500] Loss: 0.9656\n",
      "Epoch [11/80], Step [700/12500] Loss: 1.4362\n",
      "Epoch [11/80], Step [800/12500] Loss: 1.8356\n",
      "Epoch [11/80], Step [900/12500] Loss: 0.5963\n",
      "Epoch [11/80], Step [1000/12500] Loss: 0.5614\n",
      "Epoch [11/80], Step [1100/12500] Loss: 1.4122\n",
      "Epoch [11/80], Step [1200/12500] Loss: 0.0478\n",
      "Epoch [11/80], Step [1300/12500] Loss: 0.9835\n",
      "Epoch [11/80], Step [1400/12500] Loss: 0.5664\n",
      "Epoch [11/80], Step [1500/12500] Loss: 0.0096\n",
      "Epoch [11/80], Step [1600/12500] Loss: 0.0541\n",
      "Epoch [11/80], Step [1700/12500] Loss: 0.4044\n",
      "Epoch [11/80], Step [1800/12500] Loss: 0.0262\n",
      "Epoch [11/80], Step [1900/12500] Loss: 0.3268\n",
      "Epoch [11/80], Step [2000/12500] Loss: 0.4526\n",
      "Epoch [11/80], Step [2100/12500] Loss: 0.3330\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/80], Step [2200/12500] Loss: 0.2201\n",
      "Epoch [11/80], Step [2300/12500] Loss: 0.3158\n",
      "Epoch [11/80], Step [2400/12500] Loss: 1.0479\n",
      "Epoch [11/80], Step [2500/12500] Loss: 0.7308\n",
      "Epoch [11/80], Step [2600/12500] Loss: 0.7825\n",
      "Epoch [11/80], Step [2700/12500] Loss: 0.6348\n",
      "Epoch [11/80], Step [2800/12500] Loss: 0.1355\n",
      "Epoch [11/80], Step [2900/12500] Loss: 0.0989\n",
      "Epoch [11/80], Step [3000/12500] Loss: 0.0685\n",
      "Epoch [11/80], Step [3100/12500] Loss: 0.2985\n",
      "Epoch [11/80], Step [3200/12500] Loss: 0.1977\n",
      "Epoch [11/80], Step [3300/12500] Loss: 0.7831\n",
      "Epoch [11/80], Step [3400/12500] Loss: 0.8189\n",
      "Epoch [11/80], Step [3500/12500] Loss: 0.3862\n",
      "Epoch [11/80], Step [3600/12500] Loss: 0.3209\n",
      "Epoch [11/80], Step [3700/12500] Loss: 0.6141\n",
      "Epoch [11/80], Step [3800/12500] Loss: 0.9329\n",
      "Epoch [11/80], Step [3900/12500] Loss: 1.2465\n",
      "Epoch [11/80], Step [4000/12500] Loss: 0.2962\n",
      "Epoch [11/80], Step [4100/12500] Loss: 0.1557\n",
      "Epoch [11/80], Step [4200/12500] Loss: 1.0872\n",
      "Epoch [11/80], Step [4300/12500] Loss: 0.0660\n",
      "Epoch [11/80], Step [4400/12500] Loss: 0.1267\n",
      "Epoch [11/80], Step [4500/12500] Loss: 0.2773\n",
      "Epoch [11/80], Step [4600/12500] Loss: 1.2310\n",
      "Epoch [11/80], Step [4700/12500] Loss: 0.2297\n",
      "Epoch [11/80], Step [4800/12500] Loss: 0.3073\n",
      "Epoch [11/80], Step [4900/12500] Loss: 0.2665\n",
      "Epoch [11/80], Step [5000/12500] Loss: 0.7053\n",
      "Epoch [11/80], Step [5100/12500] Loss: 0.0291\n",
      "Epoch [11/80], Step [5200/12500] Loss: 0.3861\n",
      "Epoch [11/80], Step [5300/12500] Loss: 1.0959\n",
      "Epoch [11/80], Step [5400/12500] Loss: 1.0984\n",
      "Epoch [11/80], Step [5500/12500] Loss: 0.5335\n",
      "Epoch [11/80], Step [5600/12500] Loss: 0.0593\n",
      "Epoch [11/80], Step [5700/12500] Loss: 1.5930\n",
      "Epoch [11/80], Step [5800/12500] Loss: 0.4976\n",
      "Epoch [11/80], Step [5900/12500] Loss: 0.3931\n",
      "Epoch [11/80], Step [6000/12500] Loss: 0.4300\n",
      "Epoch [11/80], Step [6100/12500] Loss: 0.1562\n",
      "Epoch [11/80], Step [6200/12500] Loss: 0.6313\n",
      "Epoch [11/80], Step [6300/12500] Loss: 0.0325\n",
      "Epoch [11/80], Step [6400/12500] Loss: 0.1683\n",
      "Epoch [11/80], Step [6500/12500] Loss: 0.9893\n",
      "Epoch [11/80], Step [6600/12500] Loss: 0.9081\n",
      "Epoch [11/80], Step [6700/12500] Loss: 0.1330\n",
      "Epoch [11/80], Step [6800/12500] Loss: 0.3492\n",
      "Epoch [11/80], Step [6900/12500] Loss: 1.7826\n",
      "Epoch [11/80], Step [7000/12500] Loss: 0.1739\n",
      "Epoch [11/80], Step [7100/12500] Loss: 0.0561\n",
      "Epoch [11/80], Step [7200/12500] Loss: 0.4743\n",
      "Epoch [11/80], Step [7300/12500] Loss: 0.1300\n",
      "Epoch [11/80], Step [7400/12500] Loss: 1.6166\n",
      "Epoch [11/80], Step [7500/12500] Loss: 0.7082\n",
      "Epoch [11/80], Step [7600/12500] Loss: 0.5574\n",
      "Epoch [11/80], Step [7700/12500] Loss: 0.4165\n",
      "Epoch [11/80], Step [7800/12500] Loss: 1.2709\n",
      "Epoch [11/80], Step [7900/12500] Loss: 0.1028\n",
      "Epoch [11/80], Step [8000/12500] Loss: 1.2655\n",
      "Epoch [11/80], Step [8100/12500] Loss: 0.3389\n",
      "Epoch [11/80], Step [8200/12500] Loss: 0.2867\n",
      "Epoch [11/80], Step [8300/12500] Loss: 1.0731\n",
      "Epoch [11/80], Step [8400/12500] Loss: 0.4837\n",
      "Epoch [11/80], Step [8500/12500] Loss: 0.0176\n",
      "Epoch [11/80], Step [8600/12500] Loss: 1.5080\n",
      "Epoch [11/80], Step [8700/12500] Loss: 0.0176\n",
      "Epoch [11/80], Step [8800/12500] Loss: 0.2549\n",
      "Epoch [11/80], Step [8900/12500] Loss: 1.4286\n",
      "Epoch [11/80], Step [9000/12500] Loss: 1.8341\n",
      "Epoch [11/80], Step [9100/12500] Loss: 0.0672\n",
      "Epoch [11/80], Step [9200/12500] Loss: 0.2624\n",
      "Epoch [11/80], Step [9300/12500] Loss: 0.4718\n",
      "Epoch [11/80], Step [9400/12500] Loss: 0.0231\n",
      "Epoch [11/80], Step [9500/12500] Loss: 0.1749\n",
      "Epoch [11/80], Step [9600/12500] Loss: 0.0539\n",
      "Epoch [11/80], Step [9700/12500] Loss: 0.4157\n",
      "Epoch [11/80], Step [9800/12500] Loss: 0.6649\n",
      "Epoch [11/80], Step [9900/12500] Loss: 0.2989\n",
      "Epoch [11/80], Step [10000/12500] Loss: 0.0847\n",
      "Epoch [11/80], Step [10100/12500] Loss: 0.5565\n",
      "Epoch [11/80], Step [10200/12500] Loss: 0.6478\n",
      "Epoch [11/80], Step [10300/12500] Loss: 0.7812\n",
      "Epoch [11/80], Step [10400/12500] Loss: 0.4846\n",
      "Epoch [11/80], Step [10500/12500] Loss: 0.5090\n",
      "Epoch [11/80], Step [10600/12500] Loss: 0.3530\n",
      "Epoch [11/80], Step [10700/12500] Loss: 1.9670\n",
      "Epoch [11/80], Step [10800/12500] Loss: 0.1439\n",
      "Epoch [11/80], Step [10900/12500] Loss: 0.4399\n",
      "Epoch [11/80], Step [11000/12500] Loss: 0.0465\n",
      "Epoch [11/80], Step [11100/12500] Loss: 1.4234\n",
      "Epoch [11/80], Step [11200/12500] Loss: 0.7312\n",
      "Epoch [11/80], Step [11300/12500] Loss: 0.6336\n",
      "Epoch [11/80], Step [11400/12500] Loss: 0.1039\n",
      "Epoch [11/80], Step [11500/12500] Loss: 0.9229\n",
      "Epoch [11/80], Step [11600/12500] Loss: 0.5086\n",
      "Epoch [11/80], Step [11700/12500] Loss: 0.0673\n",
      "Epoch [11/80], Step [11800/12500] Loss: 1.1113\n",
      "Epoch [11/80], Step [11900/12500] Loss: 1.5141\n",
      "Epoch [11/80], Step [12000/12500] Loss: 0.0200\n",
      "Epoch [11/80], Step [12100/12500] Loss: 0.5699\n",
      "Epoch [11/80], Step [12200/12500] Loss: 0.1185\n",
      "Epoch [11/80], Step [12300/12500] Loss: 1.8387\n",
      "Epoch [11/80], Step [12400/12500] Loss: 0.3549\n",
      "Epoch [11/80], Step [12500/12500] Loss: 0.1005\n",
      "Epoch [12/80], Step [100/12500] Loss: 0.0598\n",
      "Epoch [12/80], Step [200/12500] Loss: 0.5892\n",
      "Epoch [12/80], Step [300/12500] Loss: 0.2928\n",
      "Epoch [12/80], Step [400/12500] Loss: 0.0937\n",
      "Epoch [12/80], Step [500/12500] Loss: 0.8560\n",
      "Epoch [12/80], Step [600/12500] Loss: 0.9718\n",
      "Epoch [12/80], Step [700/12500] Loss: 0.1184\n",
      "Epoch [12/80], Step [800/12500] Loss: 0.1233\n",
      "Epoch [12/80], Step [900/12500] Loss: 0.2725\n",
      "Epoch [12/80], Step [1000/12500] Loss: 0.4196\n",
      "Epoch [12/80], Step [1100/12500] Loss: 0.2643\n",
      "Epoch [12/80], Step [1200/12500] Loss: 0.6566\n",
      "Epoch [12/80], Step [1300/12500] Loss: 1.3353\n",
      "Epoch [12/80], Step [1400/12500] Loss: 0.2963\n",
      "Epoch [12/80], Step [1500/12500] Loss: 0.0608\n",
      "Epoch [12/80], Step [1600/12500] Loss: 0.0420\n",
      "Epoch [12/80], Step [1700/12500] Loss: 0.0090\n",
      "Epoch [12/80], Step [1800/12500] Loss: 0.1866\n",
      "Epoch [12/80], Step [1900/12500] Loss: 0.1833\n",
      "Epoch [12/80], Step [2000/12500] Loss: 0.9195\n",
      "Epoch [12/80], Step [2100/12500] Loss: 0.8084\n",
      "Epoch [12/80], Step [2200/12500] Loss: 0.3812\n",
      "Epoch [12/80], Step [2300/12500] Loss: 0.0778\n",
      "Epoch [12/80], Step [2400/12500] Loss: 0.0598\n",
      "Epoch [12/80], Step [2500/12500] Loss: 0.4541\n",
      "Epoch [12/80], Step [2600/12500] Loss: 0.5163\n",
      "Epoch [12/80], Step [2700/12500] Loss: 0.9136\n",
      "Epoch [12/80], Step [2800/12500] Loss: 0.2220\n",
      "Epoch [12/80], Step [2900/12500] Loss: 0.5924\n",
      "Epoch [12/80], Step [3000/12500] Loss: 0.9498\n",
      "Epoch [12/80], Step [3100/12500] Loss: 0.6361\n",
      "Epoch [12/80], Step [3200/12500] Loss: 1.0260\n",
      "Epoch [12/80], Step [3300/12500] Loss: 0.0385\n",
      "Epoch [12/80], Step [3400/12500] Loss: 1.0546\n",
      "Epoch [12/80], Step [3500/12500] Loss: 0.0399\n",
      "Epoch [12/80], Step [3600/12500] Loss: 0.0201\n",
      "Epoch [12/80], Step [3700/12500] Loss: 0.3117\n",
      "Epoch [12/80], Step [3800/12500] Loss: 0.1328\n",
      "Epoch [12/80], Step [3900/12500] Loss: 1.3166\n",
      "Epoch [12/80], Step [4000/12500] Loss: 0.5518\n",
      "Epoch [12/80], Step [4100/12500] Loss: 0.1523\n",
      "Epoch [12/80], Step [4200/12500] Loss: 0.4037\n",
      "Epoch [12/80], Step [4300/12500] Loss: 0.1782\n",
      "Epoch [12/80], Step [4400/12500] Loss: 0.8108\n",
      "Epoch [12/80], Step [4500/12500] Loss: 0.6732\n",
      "Epoch [12/80], Step [4600/12500] Loss: 0.8690\n",
      "Epoch [12/80], Step [4700/12500] Loss: 0.8932\n",
      "Epoch [12/80], Step [4800/12500] Loss: 1.3942\n",
      "Epoch [12/80], Step [4900/12500] Loss: 1.1438\n",
      "Epoch [12/80], Step [5000/12500] Loss: 0.8991\n",
      "Epoch [12/80], Step [5100/12500] Loss: 1.1142\n",
      "Epoch [12/80], Step [5200/12500] Loss: 0.0982\n",
      "Epoch [12/80], Step [5300/12500] Loss: 0.3120\n",
      "Epoch [12/80], Step [5400/12500] Loss: 0.3634\n",
      "Epoch [12/80], Step [5500/12500] Loss: 0.2402\n",
      "Epoch [12/80], Step [5600/12500] Loss: 0.0925\n",
      "Epoch [12/80], Step [5700/12500] Loss: 0.6538\n",
      "Epoch [12/80], Step [5800/12500] Loss: 0.0284\n",
      "Epoch [12/80], Step [5900/12500] Loss: 0.5875\n",
      "Epoch [12/80], Step [6000/12500] Loss: 0.0447\n",
      "Epoch [12/80], Step [6100/12500] Loss: 0.2727\n",
      "Epoch [12/80], Step [6200/12500] Loss: 0.0435\n",
      "Epoch [12/80], Step [6300/12500] Loss: 1.0004\n",
      "Epoch [12/80], Step [6400/12500] Loss: 0.5128\n",
      "Epoch [12/80], Step [6500/12500] Loss: 0.0262\n",
      "Epoch [12/80], Step [6600/12500] Loss: 0.4407\n",
      "Epoch [12/80], Step [6700/12500] Loss: 0.8006\n",
      "Epoch [12/80], Step [6800/12500] Loss: 0.2141\n",
      "Epoch [12/80], Step [6900/12500] Loss: 0.6638\n",
      "Epoch [12/80], Step [7000/12500] Loss: 0.2253\n",
      "Epoch [12/80], Step [7100/12500] Loss: 1.5161\n",
      "Epoch [12/80], Step [7200/12500] Loss: 1.0879\n",
      "Epoch [12/80], Step [7300/12500] Loss: 0.1392\n",
      "Epoch [12/80], Step [7400/12500] Loss: 0.6350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/80], Step [7500/12500] Loss: 0.6855\n",
      "Epoch [12/80], Step [7600/12500] Loss: 0.8216\n",
      "Epoch [12/80], Step [7700/12500] Loss: 0.3803\n",
      "Epoch [12/80], Step [7800/12500] Loss: 0.0062\n",
      "Epoch [12/80], Step [7900/12500] Loss: 0.3587\n",
      "Epoch [12/80], Step [8000/12500] Loss: 1.0600\n",
      "Epoch [12/80], Step [8100/12500] Loss: 0.2864\n",
      "Epoch [12/80], Step [8200/12500] Loss: 0.0742\n",
      "Epoch [12/80], Step [8300/12500] Loss: 0.0900\n",
      "Epoch [12/80], Step [8400/12500] Loss: 0.7614\n",
      "Epoch [12/80], Step [8500/12500] Loss: 0.6204\n",
      "Epoch [12/80], Step [8600/12500] Loss: 0.9026\n",
      "Epoch [12/80], Step [8700/12500] Loss: 0.1496\n",
      "Epoch [12/80], Step [8800/12500] Loss: 0.7424\n",
      "Epoch [12/80], Step [8900/12500] Loss: 0.8605\n",
      "Epoch [12/80], Step [9000/12500] Loss: 0.1524\n",
      "Epoch [12/80], Step [9100/12500] Loss: 1.2838\n",
      "Epoch [12/80], Step [9200/12500] Loss: 0.5440\n",
      "Epoch [12/80], Step [9300/12500] Loss: 0.9153\n",
      "Epoch [12/80], Step [9400/12500] Loss: 0.3330\n",
      "Epoch [12/80], Step [9500/12500] Loss: 0.2600\n",
      "Epoch [12/80], Step [9600/12500] Loss: 0.5461\n",
      "Epoch [12/80], Step [9700/12500] Loss: 0.7163\n",
      "Epoch [12/80], Step [9800/12500] Loss: 1.6179\n",
      "Epoch [12/80], Step [9900/12500] Loss: 0.2287\n",
      "Epoch [12/80], Step [10000/12500] Loss: 0.6903\n",
      "Epoch [12/80], Step [10100/12500] Loss: 0.1683\n",
      "Epoch [12/80], Step [10200/12500] Loss: 1.6641\n",
      "Epoch [12/80], Step [10300/12500] Loss: 0.6175\n",
      "Epoch [12/80], Step [10400/12500] Loss: 0.0745\n",
      "Epoch [12/80], Step [10500/12500] Loss: 0.0111\n",
      "Epoch [12/80], Step [10600/12500] Loss: 0.3456\n",
      "Epoch [12/80], Step [10700/12500] Loss: 0.2408\n",
      "Epoch [12/80], Step [10800/12500] Loss: 0.9170\n",
      "Epoch [12/80], Step [10900/12500] Loss: 1.4509\n",
      "Epoch [12/80], Step [11000/12500] Loss: 1.8861\n",
      "Epoch [12/80], Step [11100/12500] Loss: 0.0819\n",
      "Epoch [12/80], Step [11200/12500] Loss: 0.4851\n",
      "Epoch [12/80], Step [11300/12500] Loss: 0.2949\n",
      "Epoch [12/80], Step [11400/12500] Loss: 0.2611\n",
      "Epoch [12/80], Step [11500/12500] Loss: 0.1675\n",
      "Epoch [12/80], Step [11600/12500] Loss: 0.0656\n",
      "Epoch [12/80], Step [11700/12500] Loss: 0.7079\n",
      "Epoch [12/80], Step [11800/12500] Loss: 0.1893\n",
      "Epoch [12/80], Step [11900/12500] Loss: 0.7668\n",
      "Epoch [12/80], Step [12000/12500] Loss: 0.1877\n",
      "Epoch [12/80], Step [12100/12500] Loss: 0.8257\n",
      "Epoch [12/80], Step [12200/12500] Loss: 0.1958\n",
      "Epoch [12/80], Step [12300/12500] Loss: 0.1382\n",
      "Epoch [12/80], Step [12400/12500] Loss: 0.0897\n",
      "Epoch [12/80], Step [12500/12500] Loss: 0.3056\n",
      "Epoch [13/80], Step [100/12500] Loss: 0.0943\n",
      "Epoch [13/80], Step [200/12500] Loss: 0.2189\n",
      "Epoch [13/80], Step [300/12500] Loss: 0.4172\n",
      "Epoch [13/80], Step [400/12500] Loss: 0.1638\n",
      "Epoch [13/80], Step [500/12500] Loss: 0.0820\n",
      "Epoch [13/80], Step [600/12500] Loss: 0.5861\n",
      "Epoch [13/80], Step [700/12500] Loss: 0.1472\n",
      "Epoch [13/80], Step [800/12500] Loss: 0.2193\n",
      "Epoch [13/80], Step [900/12500] Loss: 0.0250\n",
      "Epoch [13/80], Step [1000/12500] Loss: 0.2666\n",
      "Epoch [13/80], Step [1100/12500] Loss: 0.1312\n",
      "Epoch [13/80], Step [1200/12500] Loss: 0.1078\n",
      "Epoch [13/80], Step [1300/12500] Loss: 0.8212\n",
      "Epoch [13/80], Step [1400/12500] Loss: 0.5950\n",
      "Epoch [13/80], Step [1500/12500] Loss: 0.6504\n",
      "Epoch [13/80], Step [1600/12500] Loss: 0.1480\n",
      "Epoch [13/80], Step [1700/12500] Loss: 0.1109\n",
      "Epoch [13/80], Step [1800/12500] Loss: 0.0402\n",
      "Epoch [13/80], Step [1900/12500] Loss: 0.0623\n",
      "Epoch [13/80], Step [2000/12500] Loss: 1.1233\n",
      "Epoch [13/80], Step [2100/12500] Loss: 0.2769\n",
      "Epoch [13/80], Step [2200/12500] Loss: 0.9983\n",
      "Epoch [13/80], Step [2300/12500] Loss: 0.2696\n",
      "Epoch [13/80], Step [2400/12500] Loss: 0.6880\n",
      "Epoch [13/80], Step [2500/12500] Loss: 0.7575\n",
      "Epoch [13/80], Step [2600/12500] Loss: 0.0303\n",
      "Epoch [13/80], Step [2700/12500] Loss: 0.0652\n",
      "Epoch [13/80], Step [2800/12500] Loss: 0.0979\n",
      "Epoch [13/80], Step [2900/12500] Loss: 0.1428\n",
      "Epoch [13/80], Step [3000/12500] Loss: 1.3664\n",
      "Epoch [13/80], Step [3100/12500] Loss: 0.4766\n",
      "Epoch [13/80], Step [3200/12500] Loss: 0.1806\n",
      "Epoch [13/80], Step [3300/12500] Loss: 0.6017\n",
      "Epoch [13/80], Step [3400/12500] Loss: 1.4807\n",
      "Epoch [13/80], Step [3500/12500] Loss: 0.1970\n",
      "Epoch [13/80], Step [3600/12500] Loss: 1.0259\n",
      "Epoch [13/80], Step [3700/12500] Loss: 0.3618\n",
      "Epoch [13/80], Step [3800/12500] Loss: 0.8221\n",
      "Epoch [13/80], Step [3900/12500] Loss: 0.8636\n",
      "Epoch [13/80], Step [4000/12500] Loss: 0.1452\n",
      "Epoch [13/80], Step [4100/12500] Loss: 1.3360\n",
      "Epoch [13/80], Step [4200/12500] Loss: 0.0859\n",
      "Epoch [13/80], Step [4300/12500] Loss: 0.2637\n",
      "Epoch [13/80], Step [4400/12500] Loss: 0.1497\n",
      "Epoch [13/80], Step [4500/12500] Loss: 0.1259\n",
      "Epoch [13/80], Step [4600/12500] Loss: 1.5647\n",
      "Epoch [13/80], Step [4700/12500] Loss: 0.3854\n",
      "Epoch [13/80], Step [4800/12500] Loss: 0.1238\n",
      "Epoch [13/80], Step [4900/12500] Loss: 0.1884\n",
      "Epoch [13/80], Step [5000/12500] Loss: 0.6478\n",
      "Epoch [13/80], Step [5100/12500] Loss: 0.3317\n",
      "Epoch [13/80], Step [5200/12500] Loss: 0.3704\n",
      "Epoch [13/80], Step [5300/12500] Loss: 0.1995\n",
      "Epoch [13/80], Step [5400/12500] Loss: 0.9055\n",
      "Epoch [13/80], Step [5500/12500] Loss: 0.3132\n",
      "Epoch [13/80], Step [5600/12500] Loss: 0.0154\n",
      "Epoch [13/80], Step [5700/12500] Loss: 0.1458\n",
      "Epoch [13/80], Step [5800/12500] Loss: 0.0381\n",
      "Epoch [13/80], Step [5900/12500] Loss: 0.0245\n",
      "Epoch [13/80], Step [6000/12500] Loss: 0.6777\n",
      "Epoch [13/80], Step [6100/12500] Loss: 0.3107\n",
      "Epoch [13/80], Step [6200/12500] Loss: 0.5545\n",
      "Epoch [13/80], Step [6300/12500] Loss: 1.7315\n",
      "Epoch [13/80], Step [6400/12500] Loss: 0.2954\n",
      "Epoch [13/80], Step [6500/12500] Loss: 0.9225\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-1015ab6ed1f4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m100\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m     99\u001b[0m                     \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax_exp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'eps'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m                     \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'eps'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m                 \u001b[0mbias_correction1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta1\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'step'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "total_step = len(trainloader)\n",
    "curr_lr = learning_rate\n",
    "for epoch in range(num_epochs):\n",
    "    for i,(images,labels) in enumerate(trainloader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs,labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (i+1) % 100 == 0:\n",
    "            print (\"Epoch [{}/{}], Step [{}/{}] Loss: {:.4f}\"\n",
    "                   .format(epoch+1, num_epochs, i+1, total_step, loss.item()))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
