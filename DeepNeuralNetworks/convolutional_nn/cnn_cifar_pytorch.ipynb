{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))])\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "trainloader = torch.utils.data.DataLoader(dataset=trainset,batch_size=4,\n",
    "                                         shuffle=True,num_workers=2)\n",
    "testset = torchvision.datasets.CIFAR10(root='./data',train=False,download=True,transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(dataset=testset,batch_size=4,shuffle=True)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "imshow(trainset[100][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=400, out_features=160, bias=True)\n",
      "  (fc2): Linear(in_features=160, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3,6,5)\n",
    "        self.pool = nn.MaxPool2d(2,2)\n",
    "        self.conv2 = nn.Conv2d(6,16,5)\n",
    "        self.fc1 = nn.Linear(16*5*5,160)\n",
    "        self.fc2 = nn.Linear(160,84)\n",
    "        self.fc3 = nn.Linear(84,10)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1,16*5*5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "net = Net()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(),lr=0.001,momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  2000] loss: 1.764\n",
      "[1,  4000] loss: 1.647\n",
      "[1,  6000] loss: 1.544\n",
      "[1,  8000] loss: 1.489\n",
      "[1, 10000] loss: 1.458\n",
      "[1, 12000] loss: 1.401\n",
      "[2,  2000] loss: 1.334\n",
      "[2,  4000] loss: 1.341\n",
      "[2,  6000] loss: 1.292\n",
      "[2,  8000] loss: 1.290\n",
      "[2, 10000] loss: 1.257\n",
      "[2, 12000] loss: 1.237\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(2):\n",
    "    running_loss = 0.0\n",
    "    for i,data in enumerate(trainloader,0):\n",
    "        inputs,labels = data\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs) ## why not net.forward(inputs)\n",
    "        loss = criterion(outputs,labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = './cifar_net.pth'\n",
    "torch.save(net.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the previously trained network to get the weights\n",
    "net = Net()\n",
    "net.load_state_dict(torch.load(PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 3, 32, 32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f37a3017048>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_iter = iter(testloader)\n",
    "test_img,test_label = next(test_iter)\n",
    "print(np.shape(test_img.numpy()))\n",
    "plt.imshow(np.transpose(test_img.numpy(),(0,2,3,1))[0])\n",
    "#outputs = net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4321\n"
     ]
    }
   ],
   "source": [
    "test_error = 0\n",
    "with torch.no_grad():\n",
    "    for _,data in enumerate(testloader,0):\n",
    "        test_img,test_label = data\n",
    "        test_out = net(test_img)\n",
    "        test_prediction = torch.argmax(test_out,1)\n",
    "        test_error += (test_prediction != test_label).sum().item()\n",
    "        \n",
    "print(test_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error 0.432100\n"
     ]
    }
   ],
   "source": [
    "print('Test Error %f'%(test_error/len(testset)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's do the same on the GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "(6, 1)\n",
      "GeForce GTX 1050 Ti with Max-Q Design\n",
      "_CudaDeviceProperties(name='GeForce GTX 1050 Ti with Max-Q Design', major=6, minor=1, total_memory=4042MB, multi_processor_count=6)\n"
     ]
    }
   ],
   "source": [
    "## Find whether a GPU is available or not\n",
    "torch_device = \"cpu\"\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.cuda.current_device()\n",
    "    print(device)\n",
    "    print(torch.cuda.device_count())\n",
    "    print(torch.cuda.get_device_capability())\n",
    "    print(torch.cuda.get_device_name())\n",
    "    print(torch.cuda.get_device_properties(device))\n",
    "    \n",
    "    # getting the default cuda device\n",
    "    torch_device = torch.device('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch_device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  2000] loss: 2.182\n",
      "[1,  4000] loss: 1.840\n",
      "[1,  6000] loss: 1.682\n",
      "[1,  8000] loss: 1.581\n",
      "[1, 10000] loss: 1.501\n",
      "[1, 12000] loss: 1.445\n",
      "[2,  2000] loss: 1.379\n",
      "[2,  4000] loss: 1.343\n",
      "[2,  6000] loss: 1.326\n",
      "[2,  8000] loss: 1.291\n",
      "[2, 10000] loss: 1.311\n",
      "[2, 12000] loss: 1.280\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "## retrain on GPU\n",
    "# sending network to the GPU\n",
    "net_gpu = Net()\n",
    "net_gpu.to(torch_device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net_gpu.parameters(),lr=0.001,momentum=0.9)\n",
    "\n",
    "for epoch in range(2):\n",
    "    running_loss = 0.0\n",
    "    for i,data in enumerate(trainloader,0):\n",
    "        inputs,labels = data[0].to(torch_device),data[1].to(torch_device)\n",
    "        #inputs,labels = data\n",
    "        #inputs = inputs.to(torch_device)\n",
    "        #labels = labels.to(torch_device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = net_gpu(inputs) ## why not net.forward(inputs)\n",
    "        loss = criterion(outputs,labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(net_gpu.parameters()).is_cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing on the GPU\n",
    "test_error = 0\n",
    "with torch.no_grad():\n",
    "    for _,data in enumerate(testloader,0):\n",
    "        test_img,test_label = data[0].to(torch_device),data[1].to(torch_device)\n",
    "        test_out = net_gpu(test_img)\n",
    "        test_prediction = torch.argmax(test_out,1)\n",
    "        test_error += (test_prediction != test_label).sum().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4502\n"
     ]
    }
   ],
   "source": [
    "print(test_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
